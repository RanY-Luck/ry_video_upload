"""
ç‹¬ç«‹è§†é¢‘å·ä¸Šä¼ å·¥å…·
åŠŸèƒ½: ä¸Šä¼  Upload/videos ç›®å½•ä¸‹å·²å»é‡çš„è§†é¢‘åˆ°è§†é¢‘å·
"""
import time
import json
import shutil
import asyncio
import os
import re
import cv2
import sys
import dashscope
import traceback
from pathlib import Path
from dashscope import MultiModalConversation
from typing import Dict
from Upload.utils.log import logger as logging
from Upload.utils.utils_common import setup_project_paths, setup_logging
from Upload.uploader.tencent_uploader.main import TencentVideo
from Upload.utils.bark_notifier import BarkNotifier
from Upload.utils.config_loader import config
from Upload.uploader.tencent_uploader.main import weixin_setup
from contextlib import contextmanager
from Upload.uploader.tencent_uploader.main import cookie_auth

# è®¾ç½®é¡¹ç›®è·¯å¾„
setup_project_paths()

# é…ç½®æ—¥å¿—
logger = setup_logging('logs/standalone_upload.log')


@contextmanager
def suppress_stderr():
    """Suppress stderr/stdout from C libraries"""
    try:
        # Save stderr
        original_stderr_fd = 2  # Standard stderr fd
        saved_stderr_fd = os.dup(original_stderr_fd)

        # Open devnull
        devnull = os.open(os.devnull, os.O_WRONLY)

        # Replace stderr with devnull
        os.dup2(devnull, original_stderr_fd)

        try:
            yield
        finally:
            # Restore stderr
            os.dup2(saved_stderr_fd, original_stderr_fd)
            os.close(saved_stderr_fd)
            os.close(devnull)
    except Exception:
        # If any OS error, just run the code
        yield


class StandaloneUploadConfig:
    """ç‹¬ç«‹ä¸Šä¼ å·¥å…·é…ç½®ç±»"""

    def __init__(self):
        # ä»é…ç½®æ–‡ä»¶åŠ è½½è·¯å¾„
        self.UPLOAD_DIR = config.get_path('upload_dir')
        self.VIDEO_DIR = config.get_path('video_output_dir')
        self.ACCOUNT_FILE = config.get_path('account_file')

        # ä»é…ç½®æ–‡ä»¶åŠ è½½ AI é…ç½®
        self.DASHSCOPE_API_KEY = config.dashscope_api_key

        # ä»é…ç½®æ–‡ä»¶åŠ è½½ä¸Šä¼ é…ç½®
        self.CATEGORY = config.upload_category
        self.PUBLISH_DATE = config.publish_date
        self.DELETE_AFTER_UPLOAD = config.delete_after_upload

        # nasç›®å½•é…ç½®
        self.NAS_DIR = config.nas_dir
        self.DOCKER_MODE = config.docker_mode

        # éªŒè¯è·¯å¾„
        self._validate_paths()

    def _validate_paths(self):
        """éªŒè¯å¿…è¦çš„è·¯å¾„æ˜¯å¦å­˜åœ¨"""
        # è‡ªåŠ¨åˆ›å»ºè§†é¢‘ç›®å½•
        self.VIDEO_DIR.mkdir(parents=True, exist_ok=True)

        # æ£€æŸ¥è´¦å·é…ç½®æ–‡ä»¶
        if not self.ACCOUNT_FILE.exists():
            logging.warning(f"è´¦å·é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.ACCOUNT_FILE}")
            logging.warning("è¯·å…ˆè¿è¡Œ Upload/vx_cookie.py è·å–è´¦å· cookie")

        logging.info(f"è§†é¢‘ç›®å½•: {self.VIDEO_DIR}")
        logging.info(f"è´¦å·é…ç½®: {self.ACCOUNT_FILE}")
        if self.NAS_DIR:
            logging.info(f"NAS ç›®å½•: {self.NAS_DIR}")
        if self.DOCKER_MODE:
            logging.info("å·²å¯ç”¨ Docker æ¨¡æ‹Ÿæ¨¡å¼")


class AIAnalyzer:
    """AI åˆ†æç±»: ä½¿ç”¨é˜¿é‡Œç™¾ç‚¼ AI åˆ†æè§†é¢‘ç”Ÿæˆæ ‡é¢˜å’Œæ ‡ç­¾"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        dashscope.api_key = api_key

    def analyze_video(self, video_path: Path, original_title: str = "") -> Dict[str, str]:
        """ä½¿ç”¨ AI åˆ†æè§†é¢‘,ç”Ÿæˆæ ‡é¢˜å’Œæ ‡ç­¾ (å¸¦é‡è¯•æœºåˆ¶)
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            original_title: åŸå§‹æ ‡é¢˜ (å¯é€‰)
        
        Returns:
            åŒ…å« title å’Œ tag çš„å­—å…¸
        """
        max_retries = 5
        retry_delay = 2

        for attempt in range(1, max_retries + 1):
            try:
                logging.info(f"AI åˆ†æè§†é¢‘: {video_path.name} (ç¬¬ {attempt}/{max_retries} æ¬¡å°è¯•)")

                messages = [
                    {
                        "role": "system",
                        "content": [{
                            "type": "text",
                            "text": """
                            ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´ç»éªŒçš„èµ„æ·±çŸ­è§†é¢‘è¿è¥ä¸“å®¶,æ“…é•¿è·¨å¹³å°å†…å®¹é‡æ„ä¸çˆ†æ¬¾å…¬å¼è®¾è®¡ã€‚
                            ä½ ä¼šåˆ†æè§†é¢‘å†…å®¹,ç»“åˆä¸­å›½ç”¨æˆ·å¿ƒç†,åˆ©ç”¨æ‚¬å¿µå‰ç½®ã€æ„Ÿå®˜åˆºæ¿€ã€è®¤çŸ¥å†²çªç­‰é’©å­è®¾è®¡çˆ†æ¬¾ä¸­æ–‡æ ‡é¢˜å’Œçƒ­é—¨ä¸­æ–‡æ ‡ç­¾ã€‚
                            æ ‡é¢˜ä¸­å¯ä»¥é€‚å½“ä½¿ç”¨1-2ä¸ªè¡¨æƒ…å›¾æ ‡,æ ‡ç­¾æ•°é‡å¤§äº8ä¸ªã€‚
                            ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºç»“æœ:
                            {
                                "title": "æ ‡é¢˜",
                                "tag": "æ ‡ç­¾1,æ ‡ç­¾2,æ ‡ç­¾3,æ ‡ç­¾4,æ ‡ç­¾5,æ ‡ç­¾6,æ ‡ç­¾7,æ ‡ç­¾8"
                            }
                            """
                        }]
                    },
                    {
                        "role": "user",
                        "content": [
                            {"video": f"file://{video_path}"},
                            {"text": f"åŸå§‹æ ‡é¢˜: {original_title}" if original_title else "è¯·åˆ†æè¿™ä¸ªè§†é¢‘"}
                        ]
                    }
                ]

                responses = MultiModalConversation.call(
                    model="qwen-vl-max-latest",
                    messages=messages,
                    stream=True,
                    incremental_output=True,
                    timeout=600  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ° 10 åˆ†é’Ÿ, é€‚åº”å¤§æ–‡ä»¶
                )

                full_content = []
                for response in responses:
                    try:
                        content = response["output"]["choices"][0]["message"]["content"]
                        if content and isinstance(content, list) and "text" in content[0]:
                            text_content = content[0]["text"]
                            full_content.append(text_content)
                    except (KeyError, IndexError) as error:
                        logging.debug(f"è§£æå“åº”æ—¶å‡ºé”™: {error}")
                    except Exception as e:
                        logging.debug(f"æœªçŸ¥é”™è¯¯: {e}")

                result_text = ''.join(full_content)
                result = json.loads(result_text)

                if result.get('title') and result.get('tag'):
                    logging.info(f"âœ… AI åˆ†æå®Œæˆ")
                    return result
                else:
                    raise ValueError("AI è¿”å›ç»“æœæ ¼å¼ä¸æ­£ç¡®")

            except Exception as e:
                logging.warning(f"âš ï¸ AI åˆ†æå¤±è´¥ (ç¬¬ {attempt} æ¬¡): {str(e)}")
                if attempt < max_retries:
                    logging.info(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                    # æ”¹ç”¨ time.sleep
                    time.sleep(retry_delay)
                else:
                    logging.error(f"âŒ AI åˆ†ææœ€ç»ˆå¤±è´¥: {video_path.name}")

        # æ‰€æœ‰é‡è¯•å¤±è´¥åè¿”å›é»˜è®¤å€¼
        return {
            'title': video_path.stem,
            'tag': 'ç”Ÿæ´»,æ—¥å¸¸,åˆ†äº«,æœ‰è¶£,æ¨è,ç²¾å½©,çƒ­é—¨,å¿…çœ‹'
        }


class VideoUploader:
    """è§†é¢‘ä¸Šä¼ ç±» (æ”¯æŒäººå·¥å®¡æ ¸)"""

    def __init__(self, config: StandaloneUploadConfig):
        self.config = config
        self.ai_analyzer = AIAnalyzer(config.DASHSCOPE_API_KEY)

        # å¦‚æœå¯ç”¨äº† Docker æ¨¡æ‹Ÿæ¨¡å¼,è®¾ç½®ç¯å¢ƒå˜é‡
        if self.config.DOCKER_MODE:
            os.environ['DOCKER_ENV'] = 'true'
            logging.info("å·²è®¾ç½®ç¯å¢ƒå˜é‡ DOCKER_ENV=true")

        # åˆå§‹åŒ–ä¸Šä¼ å†å²è®°å½•
        self.history_file = Path('logs/uploaded_history.txt')
        self.uploaded_history = self._load_history()

    def scan_video_width(self, video_path: Path) -> int:
        """è·å–è§†é¢‘å®½åº¦
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            int: è§†é¢‘å®½åº¦, å¦‚æœè·å–å¤±è´¥åˆ™è¿”å› 0
        """
        try:
            with suppress_stderr():
                cap = cv2.VideoCapture(str(video_path))
            if not cap.isOpened():
                return 0
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            cap.release()
            return width
        except ImportError:
            logging.warning("æœªå®‰è£… opencv-python, æ— æ³•è·å–è§†é¢‘åˆ†è¾¨ç‡")
            return 0
        except Exception as e:
            logging.error(f"è·å–è§†é¢‘å®½åº¦å¤±è´¥: {e}")
            return 0

    def _load_history(self) -> set:
        """åŠ è½½å·²ä¸Šä¼ è§†é¢‘çš„å†å²è®°å½•"""
        history = set()
        if self.history_file.exists():
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line:
                            history.add(line)
                logging.info(f"å·²åŠ è½½ {len(history)} æ¡ä¸Šä¼ å†å²è®°å½•")
            except Exception as e:
                logging.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
        return history

    def _save_history(self, filename: str):
        """ä¿å­˜ä¸Šä¼ è®°å½•"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            self.history_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.history_file, 'a', encoding='utf-8') as f:
                f.write(f"{filename}\n")
            self.uploaded_history.add(filename)
        except Exception as e:
            logging.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

    def fetch_from_nas(self, nas_dir: Path, target_dir: Path):
        """ä» NAS ç›®å½•æ‹‰å–è§†é¢‘æ–‡ä»¶åˆ°æœ¬åœ°
        
        Args:
            nas_dir: NAS ç›®å½•è·¯å¾„
            target_dir: æœ¬åœ°ç›®æ ‡ç›®å½•
        """
        if not nas_dir or not nas_dir.exists():
            logging.warning("NAS ç›®å½•æœªé…ç½®æˆ–ä¸å­˜åœ¨,è·³è¿‡æ‹‰å–")
            return

        logging.info(f"æ­£åœ¨ä» NAS æ‹‰å–è§†é¢‘: {nas_dir} -> {target_dir}")

        # æŸ¥æ‰¾æ‰€æœ‰ .mp4 æ–‡ä»¶
        video_files = list(nas_dir.glob('*.mp4'))
        if not video_files:
            logging.info("NAS ç›®å½•ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return

        count = 0
        for video_file in video_files:
            if count >= 1:
                logging.info("å·²è¾¾åˆ°å•æ¬¡æ‹‰å–æ•°é‡é™åˆ¶(1ä¸ª),åœæ­¢æ‹‰å–")
                break

            # å¤„ç†æ–‡ä»¶å: å»é™¤ç‰¹æ®Šç¬¦å·å’Œç©ºæ ¼
            # ä¿ç•™: ä¸­æ–‡, è‹±æ–‡, æ•°å­—
            stem = video_file.stem
            suffix = video_file.suffix

            # ä½¿ç”¨æ­£åˆ™æ›¿æ¢éä¸­æ–‡ã€éå­—æ¯ã€éæ•°å­—çš„å­—ç¬¦ä¸ºç©º
            new_stem = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9]', '', stem)

            # å¦‚æœå¤„ç†åæ–‡ä»¶åä¸ºç©º(å…¨æ˜¯ç‰¹æ®Šç¬¦å·),åˆ™ä¿ç•™åŸåæˆ–ä½¿ç”¨é»˜è®¤å
            if not new_stem:
                logging.warning(f"æ–‡ä»¶åæ¸…æ´—åä¸ºç©º: {stem}, ä½¿ç”¨åŸå")
                new_stem = stem

            new_filename = f"{new_stem}{suffix}"

            # æ£€æŸ¥æ˜¯å¦å·²ä¸Šä¼ è¿‡
            if new_filename in self.uploaded_history:
                logging.info(f"æ–‡ä»¶å·²åœ¨ä¸Šä¼ å†å²ä¸­,è·³è¿‡: {new_filename}")
                continue

            target_file = target_dir / new_filename

            if not target_file.exists():
                # è·å–æ–‡ä»¶å¤§å° (MB)
                file_size_mb = video_file.stat().st_size / (1024 * 1024)

                # è·å–è§†é¢‘å®½åº¦
                width = self.scan_video_width(video_file)

                # è‡ªåŠ¨è¿‡æ»¤: åªä¿ç•™å®½åº¦ä¸º 720 çš„è§†é¢‘
                if width != 720:
                    logging.info(f"è·³è¿‡é 720p è§†é¢‘: {video_file.name} (å®½åº¦: {width})")
                    continue

                logging.info(f"å‘ç°ç¬¦åˆæ¡ä»¶çš„è§†é¢‘: {video_file.name}")
                logging.info(f"æ¸…æ´—åå: {new_filename}")
                logging.info(f"æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
                logging.info(f"è§†é¢‘å®½åº¦: {width}")

                try:
                    logging.info(f"æ­£åœ¨å¤åˆ¶: {video_file.name} -> {new_filename}")
                    shutil.copy2(video_file, target_file)
                    count += 1
                except Exception as e:
                    logging.error(f"å¤åˆ¶å¤±è´¥ {video_file.name}: {e}")

                # å¤åˆ¶æˆåŠŸåç›´æ¥è·³å‡ºï¼ˆå› ä¸ºåªéœ€è¦ä¸€ä¸ªï¼‰
                break

            else:
                logging.debug(f"æ–‡ä»¶å·²å­˜åœ¨,è·³è¿‡: {new_filename}")

        logging.info(f"âœ… ä» NAS æ‹‰å–å®Œæˆ,æ–°å¢ {count} ä¸ªè§†é¢‘")

    async def setup_account(self) -> bool:
        """è®¾ç½®è´¦å·ç™»å½• (æ”¯æŒ cookie å¤ç”¨ + éªŒè¯ç¼“å­˜)"""
        try:
            # æ£€æŸ¥è´¦å·æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            logging.info(f"æ­£åœ¨æ£€æŸ¥è´¦å·æ–‡ä»¶: {self.config.ACCOUNT_FILE.absolute()}")
            if self.config.ACCOUNT_FILE.exists():
                logging.info("æ£€æµ‹åˆ°å·²ä¿å­˜çš„ç™»å½•çŠ¶æ€,æ­£åœ¨éªŒè¯ cookie æœ‰æ•ˆæ€§...")

                # éªŒè¯ cookie æ˜¯å¦æœ‰æ•ˆ
                is_valid = await cookie_auth(str(self.config.ACCOUNT_FILE))

                if is_valid:
                    return True
                else:
                    logging.warning("âš ï¸  Cookie å·²å¤±æ•ˆ,éœ€è¦é‡æ–°ç™»å½•")
            else:
                logging.info("æœªæ‰¾åˆ°ç™»å½•çŠ¶æ€,éœ€è¦æ‰«ç ç™»å½•")

            # Cookie ä¸å­˜åœ¨æˆ–å·²å¤±æ•ˆ,ä½¿ç”¨ weixin_setup è¿›è¡Œæ‰«ç ç™»å½•
            logging.info("ğŸ“± å‡†å¤‡æ‰«ç ç™»å½•")
            logging.info("ğŸ’¡ ç™»å½•æˆåŠŸå,cookie å°†è¢«ä¿å­˜,ä¸‹æ¬¡æ— éœ€é‡å¤æ‰«ç ")
            logging.info("â° è¯·å‡†å¤‡å¥½æ‰‹æœºå¾®ä¿¡,æµè§ˆå™¨å³å°†æ‰“å¼€...")

            # ä½¿ç”¨ weixin_setup è¿›è¡Œæ‰«ç ç™»å½•
            # handle=True ä¼šæ‰“å¼€æµè§ˆå™¨è¿›è¡Œæ‰«ç 

            success = await weixin_setup(str(self.config.ACCOUNT_FILE), handle=True)

            if success:
                logging.info("âœ… æ‰«ç ç™»å½•æˆåŠŸ,cookie å·²ä¿å­˜")
                return True
            else:
                logging.error("âŒ æ‰«ç ç™»å½•å¤±è´¥")
                return False

        except Exception as e:
            logging.error(f"âŒ è´¦å·è®¾ç½®å¤±è´¥: {e}")
            logging.error(traceback.format_exc())
            return False

    def generate_metadata_file(self, video_path: Path) -> Path:
        """ä¸ºè§†é¢‘ç”Ÿæˆå…ƒæ•°æ®æ–‡ä»¶ (æ ‡é¢˜å’Œæ ‡ç­¾)
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        
        Returns:
            å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        """
        metadata_file = video_path.with_suffix('.txt')

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨,è¯´æ˜å·²ç»ç”Ÿæˆè¿‡æˆ–ç”¨æˆ·å·²ä¿®æ”¹,ç›´æ¥è¿”å›
        if metadata_file.exists():
            logging.info(f"å…ƒæ•°æ®æ–‡ä»¶å·²å­˜åœ¨: {metadata_file.name}")
            return metadata_file

        # å…ˆåˆ›å»ºæ–‡ä»¶,å†™å…¥é»˜è®¤å†…å®¹
        logging.info(f"æ­£åœ¨ä¸º {video_path.name} ç”Ÿæˆå…ƒæ•°æ®æ–‡ä»¶...")
        with open(metadata_file, 'w', encoding='utf-8') as f:
            f.write(f"æ ‡é¢˜: æ­£åœ¨AIåˆ†æä¸­...\n")
            f.write(f"æ ‡ç­¾: æ­£åœ¨AIåˆ†æä¸­...\n")
            f.write("\n")
            f.write("# ========== ä½¿ç”¨è¯´æ˜ ==========\n")
            f.write("# ç¬¬ä¸€è¡Œæ˜¯æ ‡é¢˜ (æ ¼å¼: æ ‡é¢˜: xxx)\n")
            f.write("# ç¬¬äºŒè¡Œæ˜¯æ ‡ç­¾ (æ ¼å¼: æ ‡ç­¾: tag1,tag2,tag3)\n")
            f.write("# è¯·æ ¹æ®è§†é¢‘å†…å®¹ä¿®æ”¹æ ‡é¢˜å’Œæ ‡ç­¾\n")
            f.write("# ä¿®æ”¹å®Œæˆåä¿å­˜æ–‡ä»¶å³å¯\n")
            f.write("# ==============================\n")

        logging.info(
            f"âœ…"
            f" å·²åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶: {metadata_file.name}"
        )

        # AI åˆ†æè§†é¢‘ç”Ÿæˆæ ‡é¢˜å’Œæ ‡ç­¾
        logging.info(f"AI åˆ†æè§†é¢‘: {video_path.name}")
        ai_result = self.ai_analyzer.analyze_video(video_path)

        # æ›´æ–°æ–‡ä»¶å†…å®¹
        with open(metadata_file, 'w', encoding='utf-8') as f:
            f.write(f"æ ‡é¢˜: {ai_result['title']}\n")
            f.write(f"æ ‡ç­¾: {ai_result['tag']}\n")
            f.write("\n")
            f.write("# ========== ä½¿ç”¨è¯´æ˜ ==========\n")
            f.write("# ç¬¬ä¸€è¡Œæ˜¯æ ‡é¢˜ (æ ¼å¼: æ ‡é¢˜: xxx)\n")
            f.write("# ç¬¬äºŒè¡Œæ˜¯æ ‡ç­¾ (æ ¼å¼: æ ‡ç­¾: tag1,tag2,tag3)\n")
            f.write("# è¯·æ ¹æ®è§†é¢‘å†…å®¹ä¿®æ”¹æ ‡é¢˜å’Œæ ‡ç­¾\n")
            f.write("# ä¿®æ”¹å®Œæˆåä¿å­˜æ–‡ä»¶å³å¯\n")
            f.write("# ==============================\n")

        logging.info(f"âœ… AI åˆ†æå®Œæˆ,å·²æ›´æ–°å…ƒæ•°æ®æ–‡ä»¶")
        logging.info(f"æ ‡é¢˜: {ai_result['title']}")
        logging.info(f"æ ‡ç­¾: {ai_result['tag']}")

        return metadata_file

    def read_metadata_file(self, metadata_file: Path) -> Dict[str, any]:
        """è¯»å–å…ƒæ•°æ®æ–‡ä»¶
        
        Args:
            metadata_file: å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        
        Returns:
            åŒ…å« title å’Œ tags çš„å­—å…¸
        """
        try:
            with open(metadata_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            title = ""
            tags = []

            for line in lines:
                line = line.strip()
                if line.startswith('#') or not line:
                    continue

                if line.startswith('æ ‡é¢˜:') or line.startswith('æ ‡é¢˜ï¼š'):
                    title = line.split(':', 1)[1].strip() if ':' in line else line.split('ï¼š', 1)[1].strip()
                elif line.startswith('æ ‡ç­¾:') or line.startswith('æ ‡ç­¾ï¼š'):
                    tag_str = line.split(':', 1)[1].strip() if ':' in line else line.split('ï¼š', 1)[1].strip()
                    tags = [tag.strip() for tag in tag_str.split(',') if tag.strip()]

            if not title:
                raise ValueError("æœªæ‰¾åˆ°æ ‡é¢˜")
            if not tags:
                raise ValueError("æœªæ‰¾åˆ°æ ‡ç­¾")

            return {'title': title, 'tags': tags}

        except Exception as e:
            logging.error(f"è¯»å–å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
            raise

    async def upload_single_video(self, video_path: Path, metadata_file: Path) -> bool:
        """ä¸Šä¼ å•ä¸ªè§†é¢‘
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            metadata_file: å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        
        Returns:
            ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        try:
            logging.info(f"å¼€å§‹ä¸Šä¼ : {video_path.name}")

            # è¯»å–å…ƒæ•°æ®æ–‡ä»¶
            metadata = self.read_metadata_file(metadata_file)
            title = metadata['title']
            tags = metadata['tags']

            logging.info(f"æ ‡é¢˜: {title}")
            logging.info(f"æ ‡ç­¾: {', '.join(tags)}")

            # ä¸Šä¼ è§†é¢‘
            logging.info("æ­£åœ¨ä¸Šä¼ åˆ°è§†é¢‘å·...")
            app = TencentVideo(
                title=title,
                file_path=video_path,
                tags=tags,
                publish_date=self.config.PUBLISH_DATE,
                account_file=self.config.ACCOUNT_FILE,
                category=self.config.CATEGORY
            )
            await app.main()

            logging.info(f"âœ… ä¸Šä¼ æˆåŠŸ: {video_path.name}")

            # ä¸Šä¼ æˆåŠŸåä¿å­˜è®°å½•å¹¶åˆ é™¤è§†é¢‘å’Œå…ƒæ•°æ®æ–‡ä»¶
            self._save_history(video_path.name)

            if self.config.DELETE_AFTER_UPLOAD:
                video_path.unlink()
                metadata_file.unlink()
                logging.info(f"å·²åˆ é™¤æœ¬åœ°æ–‡ä»¶: {video_path.name} å’Œ {metadata_file.name}")

            return True

        except Exception as e:
            logging.error(f"âŒ ä¸Šä¼ å¤±è´¥: {video_path.name}")
            logging.error(f"é”™è¯¯ä¿¡æ¯: {e}")
            return False

    def generate_all_metadata(self):
        """ä¸ºæ‰€æœ‰è§†é¢‘ç”Ÿæˆå…ƒæ•°æ®æ–‡ä»¶"""
        all_video_files = list(self.config.VIDEO_DIR.glob('*.mp4'))

        # è¿‡æ»¤å·²ä¸Šä¼ çš„è§†é¢‘
        video_files = []
        for v in all_video_files:
            if v.name in self.uploaded_history:
                logging.info(f"è·³è¿‡å·²ä¸Šä¼ è§†é¢‘: {v.name}")
            else:
                video_files.append(v)

        if not video_files:
            logging.info("æ²¡æœ‰éœ€è¦ç”Ÿæˆå…ƒæ•°æ®çš„è§†é¢‘æ–‡ä»¶")
            return []

        logging.info(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")

        metadata_files = []

        for i, video_file in enumerate(video_files, 1):
            logging.info(f"è¿›åº¦: [{i}/{len(video_files)}]")
            try:
                metadata_file = self.generate_metadata_file(video_file)
                metadata_files.append((video_file, metadata_file))
            except Exception as e:
                logging.error(f"ç”Ÿæˆå…ƒæ•°æ®å¤±è´¥: {video_file.name} -> {e}")

        return metadata_files

    def notify_qr_login(self):
        """å‘é€æ‰«ç ç™»å½•é€šçŸ¥"""
        try:
            notifier = BarkNotifier(config.bark_key)
            notifier.send(
                title="ğŸ“± éœ€è¦æ‰«ç ç™»å½•",
                content="è§†é¢‘å·ä¸Šä¼ å·¥å…·éœ€æ‰«ç ç™»å½•ï¼Œè¯·å¹¶åœ¨æ§åˆ¶å°æŒ‰å›è½¦ç»§ç»­",
                level="timeSensitive",
                sound="alarm",
                group="è§†é¢‘ä¸Šä¼ ",
                icon="https://api.iconify.design/mdi:qrcode-scan.svg"
            )
        except Exception as e:
            logging.error(f"å‘é€é€šçŸ¥å¤±è´¥: {e}")

    def notify_manual_review(self, count):
        """å‘é€äººå·¥å®¡æ ¸é€šçŸ¥"""
        try:
            notifier = BarkNotifier(config.bark_key)
            notifier.send(
                title="ğŸ“ ç­‰å¾…äººå·¥å®¡æ ¸",
                content=f"å·²ç”Ÿæˆ {count} ä¸ªè§†é¢‘çš„å…ƒæ•°æ®ï¼Œè¯·å®¡æ ¸ååœ¨æ§åˆ¶å°æŒ‰å›è½¦ç»§ç»­",
                sound="minuet",
                group="è§†é¢‘ä¸Šä¼ ",
                icon="https://api.iconify.design/mdi:file-document-edit-outline.svg"
            )
        except Exception as e:
            logging.error(f"å‘é€é€šçŸ¥å¤±è´¥: {e}")

    def notify_completion(self, count, success, fail):
        """å‘é€å®Œæˆé€šçŸ¥"""
        try:
            notifier = BarkNotifier(config.bark_key)
            notifier.send(
                title="ğŸ“¤ è§†é¢‘ä¸Šä¼ å®Œæˆ",
                content=f"æ€»è®¡: {count} | æˆåŠŸ: {success} | å¤±è´¥: {fail}",
                group="è§†é¢‘ä¸Šä¼ ",
                sound="fanfare",
                icon="https://api.iconify.design/mdi:cloud-upload-outline.svg"
            )
        except Exception as e:
            logging.error(f"å‘é€é€šçŸ¥å¤±è´¥: {e}")

    async def upload_all_videos(self):
        """ä¸Šä¼ æ‰€æœ‰è§†é¢‘ (ä¼˜åŒ–åçš„æµç¨‹)"""

        # ç¬¬ä¸€æ­¥: è´¦å·ç™»å½• (æ™ºèƒ½ç™»å½•)
        logging.info("ã€ç¬¬ä¸€æ­¥ã€‘è´¦å·ç™»å½•")
        # å‘é€æ‰«ç æé†’(å¦‚æœéœ€è¦çš„è¯)
        if not self.config.ACCOUNT_FILE.exists():
            self.notify_qr_login()

        if not await self.setup_account():
            logging.error("âŒ ç™»å½•å¤±è´¥,æ— æ³•ç»§ç»­ä¸Šä¼ ")
            logging.error("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
            return

        # ç¬¬äºŒæ­¥: ä» NAS æ‹‰å–è§†é¢‘
        if self.config.NAS_DIR:
            logging.info("ã€ç¬¬äºŒæ­¥ã€‘ä» NAS æ‹‰å–è§†é¢‘")

            # æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²æœ‰å¾…ä¸Šä¼ çš„è§†é¢‘ (MP4 + TXT)
            existing_videos = list(self.config.VIDEO_DIR.glob('*.mp4'))
            pending_videos = []
            for v in existing_videos:
                metadata_path = v.with_suffix('.txt')
                if metadata_path.exists() and v.name not in self.uploaded_history:
                    pending_videos.append(v)

            if pending_videos:
                logging.info(f"æœ¬åœ°å·²æœ‰ {len(pending_videos)} ä¸ªå¾…ä¸Šä¼ è§†é¢‘ (å·²å«å…ƒæ•°æ®), è·³è¿‡ä» NAS æ‹‰å–")
                for v in pending_videos:
                    logging.info(f"  - {v.name}")
            else:
                self.fetch_from_nas(self.config.NAS_DIR, self.config.VIDEO_DIR)

        # ç¬¬ä¸‰æ­¥: ç”Ÿæˆæ‰€æœ‰å…ƒæ•°æ®æ–‡ä»¶
        logging.info("ã€ç¬¬ä¸‰æ­¥ã€‘ç”Ÿæˆå…ƒæ•°æ®æ–‡ä»¶")
        metadata_files = self.generate_all_metadata()
        if not metadata_files:
            logging.info("æ²¡æœ‰éœ€è¦ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶")
            return
        # ç¬¬å››æ­¥: ç­‰å¾…ç”¨æˆ·å®¡æ ¸
        logging.info("ã€ç¬¬å››æ­¥ã€‘äººå·¥å®¡æ ¸")
        logging.info(f"âœ… å·²ä¸º {len(metadata_files)} ä¸ªè§†é¢‘ç”Ÿæˆå…ƒæ•°æ®æ–‡ä»¶")
        logging.info(f"ğŸ“ å…ƒæ•°æ®æ–‡ä»¶ä½ç½®: {self.config.VIDEO_DIR}")
        logging.info("ğŸ“ è¯·æ£€æŸ¥å¹¶ä¿®æ”¹æ¯ä¸ªè§†é¢‘å¯¹åº”çš„ .txt æ–‡ä»¶:")
        for video_file, metadata_file in metadata_files:
            logging.info(f"{metadata_file.name}")
        logging.info("âš ï¸  è¯·æ ¹æ®å®é™…è§†é¢‘å†…å®¹ä¿®æ”¹æ ‡é¢˜å’Œæ ‡ç­¾!")
        logging.info("âœ… ä¿®æ”¹å®Œæˆå,æŒ‰å›è½¦é”®ç»§ç»­ä¸Šä¼ ...")
        # å‘é€å®¡æ ¸æé†’
        self.notify_manual_review(len(metadata_files))

        # ç¬¬äº”æ­¥: æ‰¹é‡ä¸Šä¼ 
        logging.info("ã€ç¬¬äº”æ­¥ã€‘æ‰¹é‡ä¸Šä¼ ")

        # å†æ¬¡æ£€æŸ¥ç™»å½•çŠ¶æ€ (é˜²æ­¢åœ¨äººå·¥å®¡æ ¸æœŸé—´ session è¿‡æœŸ)
        logging.info("æ­£åœ¨éªŒè¯ç™»å½•çŠ¶æ€...")
        if not await self.setup_account():
            logging.error("âŒ ç™»å½•éªŒè¯å¤±è´¥/å·²è¿‡æœŸ,ä¸”é‡æ–°ç™»å½•å¤±è´¥,æ— æ³•ç»§ç»­")
            return

        logging.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼  {len(metadata_files)} ä¸ªè§†é¢‘...")
        success_count = 0
        fail_count = 0
        for i, (video_file, metadata_file) in enumerate(metadata_files, 1):
            logging.info(f"è¿›åº¦: [{i}/{len(metadata_files)}]")

            try:
                result = await self.upload_single_video(video_file, metadata_file)
                if result:
                    success_count += 1
                else:
                    fail_count += 1
            except Exception as e:
                fail_count += 1
                logging.error(f"ä¸Šä¼ å¼‚å¸¸: {e}")

            logging.info(f"å½“å‰ç»Ÿè®¡ - æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}")

        logging.info("ä¸Šä¼ å®Œæˆ!")
        logging.info(f"æ€»è®¡: {len(metadata_files)} ä¸ªæ–‡ä»¶")
        logging.info(f"æˆåŠŸ: {success_count} ä¸ª")
        logging.info(f"å¤±è´¥: {fail_count} ä¸ª")

        # å‘é€å®Œæˆæé†’
        self.notify_completion(len(metadata_files), success_count, fail_count)


async def main():
    """ä¸»å‡½æ•°"""
    try:
        logging.info("ç‹¬ç«‹è§†é¢‘å·ä¸Šä¼ å·¥å…·å¯åŠ¨")

        # åˆå§‹åŒ–é…ç½®
        config = StandaloneUploadConfig()

        # åˆ›å»ºä¸Šä¼ å™¨
        uploader = VideoUploader(config)

        # æ‰§è¡Œä¸Šä¼ 
        await uploader.upload_all_videos()

    except KeyboardInterrupt:
        logging.info("\nç”¨æˆ·ä¸­æ–­,ç¨‹åºé€€å‡º")
    except Exception as e:
        logging.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
