#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦åšä¸»æ–°å¸–å®æ—¶ç›‘æ§è„šæœ¬

åŠŸèƒ½ï¼š
  - æŒç»­ç›‘æ§æŒ‡å®šå°çº¢ä¹¦åšä¸»çš„ä¸»é¡µ
  - ä¸€æ—¦å‘ç°æ–°ç¬”è®°ç«‹å³ä¸‹è½½ï¼ˆå›¾ç‰‡/è§†é¢‘/æ–‡æ¡ˆï¼‰
  - é€šè¿‡ Bark æ¨é€æ–°å¸–é€šçŸ¥åˆ°æ‰‹æœº

ä½¿ç”¨æ–¹å¼ï¼š
  # è¯»å– .env ä¸­ XHS_MONITOR_USERS é…ç½®è¿è¡Œ
  python xhs_monitor.py

  # æŒ‡å®šåšä¸»è¿è¡Œ
  python xhs_monitor.py --users "https://www.xiaohongshu.com/user/profile/xxx"

  # è‡ªå®šä¹‰æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
  python xhs_monitor.py --interval 300

  # ä»…æ£€æŸ¥ä¸€æ¬¡ä¸å¾ªç¯
  python xhs_monitor.py --once

  # æŒ‡å®šå¤šä¸ªåšä¸»
  python xhs_monitor.py --users "url1,url2"
"""

import argparse
import asyncio
import json
import logging
import os
import re
import sys
import time
import httpx
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Set
from dotenv import load_dotenv

# å°† XHS æ¨¡å—è·¯å¾„åŠ å…¥ Python æœç´¢è·¯å¾„ï¼ˆå¿…é¡»åœ¨ import XHSDownloader ä¹‹å‰ï¼‰
sys.path.insert(0, str(Path(__file__).parent / "XHS"))
from XHS.xhs_downloader import XHSDownloader

# ==========================================
# æ—¥å¿—é…ç½®
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.StreamHandler(sys.stdout),
    ],
)
logger = logging.getLogger("xhs_monitor")

# ==========================================
# å¸¸é‡
# ==========================================
USER_URL_PATTERN = re.compile(
    r"(?:https?://)?(?:www\.)?xiaohongshu\.com/user/profile/([a-zA-Z0-9_-]+)"
)


# ==========================================
# Bark æ¨é€å·¥å…·
# ==========================================
class BarkNotifier:
    """Bark iOS æ¨é€é€šçŸ¥"""

    def __init__(self, bark_key: str = ""):
        self.bark_key = bark_key or os.getenv("BARK_KEY", "").strip()
        self.base_url = "https://api.day.app"

    def is_enabled(self) -> bool:
        return bool(self.bark_key)

    async def push(
            self,
            title: str,
            body: str,
            url: str = "",
            group: str = "å°çº¢ä¹¦ç›‘æ§",
    ) -> bool:
        """å‘é€ Bark æ¨é€é€šçŸ¥ï¼ˆPOST æ–¹å¼ï¼‰"""
        if not self.is_enabled():
            logger.warning("[Bark] æœªé…ç½® BARK_KEYï¼Œè·³è¿‡æ¨é€")
            return False

        payload: Dict = {
            "title": title,
            "body": body,
            "group": group,
            "sound": "minuet",
        }
        if url:
            payload["url"] = url

        try:
            async with httpx.AsyncClient(timeout=10) as client:
                resp = await client.post(
                    f"{self.base_url}/{self.bark_key}",
                    json=payload,
                )
                if resp.status_code == 200:
                    logger.info(f"[Bark] æ¨é€æˆåŠŸ: {title}")
                    return True
                else:
                    logger.warning(f"[Bark] æ¨é€å¤±è´¥ HTTP {resp.status_code}: {resp.text}")
        except Exception as e:
            logger.error(f"[Bark] æ¨é€å¼‚å¸¸: {e}")
        return False


# ==========================================
# å•åšä¸»ç›‘æ§å™¨
# ==========================================
class XHSBloggerMonitor:
    """
    ç›‘æ§å•ä¸ªå°çº¢ä¹¦åšä¸»ï¼Œæ£€æµ‹æ–°ç¬”è®°å¹¶ä¸‹è½½ã€‚
    """

    def __init__(
            self,
            user_url: str,
            download_dir: str,
            downloader: XHSDownloader,
            notifier: BarkNotifier,
            seen_file_dir: Path,
            cookie: str = "",
    ):
        """
        Args:
            user_url: åšä¸»ä¸»é¡µå®Œæ•´ URL
            download_dir: ä¸‹è½½æ ¹ç›®å½•
            downloader: å·²åˆå§‹åŒ–çš„ XHSDownloader å®ä¾‹
            notifier: Bark æ¨é€å®ä¾‹
            seen_file_dir: å·²çŸ¥ç¬”è®° ID è®°å½•æ–‡ä»¶ç›®å½•
            cookie: å°çº¢ä¹¦ Cookie
        """
        self.user_url = user_url
        self.user_id = self._extract_user_id(user_url)
        self.download_dir = Path(download_dir)
        self.downloader = downloader
        self.notifier = notifier
        self.cookie = cookie or os.getenv("XHS_COOKIE", "")

        # å·²çŸ¥ç¬”è®° ID æŒä¹…åŒ–æ–‡ä»¶
        self.seen_file = seen_file_dir / f"{self.user_id}_seen.json"

        # åšä¸»æ˜µç§°ï¼ˆé¦–æ¬¡è·å–åç¼“å­˜ï¼‰
        self.author_name: str = ""

        # å†…å­˜ä¸­çš„å·²çŸ¥ç¬”è®°é›†åˆ
        self._seen_ids: Set[str] = self._load_seen_ids()

        logger.info(f"[åˆå§‹åŒ–] åšä¸» {self.user_id}ï¼Œå·²çŸ¥ç¬”è®°æ•°: {len(self._seen_ids)}")

    @staticmethod
    def _extract_user_id(url: str) -> str:
        """ä» URL ä¸­æå–ç”¨æˆ· ID"""
        match = USER_URL_PATTERN.search(url)
        return match.group(1) if match else url.strip()

    def _load_seen_ids(self) -> Set[str]:
        """ä»ç£ç›˜åŠ è½½å·²çŸ¥ç¬”è®° ID"""
        if not self.seen_file.exists():
            return set()
        try:
            with open(self.seen_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                return set(data.get("seen_ids", []))
        except Exception as e:
            logger.warning(f"[è®°å½•] è¯»å–è®°å½•æ–‡ä»¶å¤±è´¥: {e}")
            return set()

    def _save_seen_ids(self):
        """å°†å·²çŸ¥ç¬”è®° ID æŒä¹…åŒ–åˆ°ç£ç›˜"""
        try:
            self.seen_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.seen_file, "w", encoding="utf-8") as f:
                json.dump(
                    {
                        "user_id": self.user_id,
                        "author_name": self.author_name,
                        "seen_ids": list(self._seen_ids),
                        "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    },
                    f,
                    ensure_ascii=False,
                    indent=2,
                )
        except Exception as e:
            logger.error(f"[è®°å½•] ä¿å­˜è®°å½•æ–‡ä»¶å¤±è´¥: {e}")

    async def fetch_latest_notes(self) -> List[Dict]:
        """
        ä½¿ç”¨ Playwright è®¿é—®åšä¸»ä¸»é¡µï¼Œé€šè¿‡ DOM è§£æ + __INITIAL_STATE__ æå–ç¬”è®°åˆ—è¡¨ã€‚
        ï¼ˆä¸å†ä¾èµ– API æ‹¦æˆªï¼Œå› ä¸ºå°çº¢ä¹¦å®‰å…¨ç›¾ä¼šé˜»æ­¢ user_posted API çš„å‘èµ·ï¼‰

        Returns:
            ç¬”è®°ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« note_id, title, xsec_token, note_url
        """
        try:
            from playwright.async_api import async_playwright
        except ImportError:
            logger.error("[Playwright] æœªå®‰è£… Playwrightï¼Œè¯·è¿è¡Œ: pip install playwright && playwright install chromium")
            return []

        captured: Dict[str, Dict] = {}
        page_user_name = ""

        user_profile_url = f"https://www.xiaohongshu.com/user/profile/{self.user_id}"

        async with async_playwright() as p:
            logger.info(f"[æµè§ˆå™¨] å¯åŠ¨ Chromium æ£€æŸ¥åšä¸» {self.user_id}...")

            browser = await p.chromium.launch(
                headless=False,
                args=[
                    "--disable-blink-features=AutomationControlled",
                    "--no-sandbox",
                    "--disable-dev-shm-usage",
                    "--disable-infobars",
                    "--window-size=1280,900",
                ],
            )
            context = await browser.new_context(
                user_agent=(
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/120.0.0.0 Safari/537.36"
                ),
                viewport={"width": 1280, "height": 900},
                locale="zh-CN",
            )

            # æ³¨å…¥åæ£€æµ‹è„šæœ¬ï¼ˆéšè— webdriver æ ‡è®°ï¼‰
            await context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                window.chrome = {runtime: {}};
            """)

            # æ³¨å…¥ Cookie
            if self.cookie:
                cookies = []
                for item in self.cookie.split(";"):
                    item = item.strip()
                    if "=" in item:
                        name, value = item.split("=", 1)
                        cookies.append({
                            "name": name.strip(),
                            "value": value.strip(),
                            "domain": ".xiaohongshu.com",
                            "path": "/",
                        })
                if cookies:
                    await context.add_cookies(cookies)
                    logger.info(f"[æµè§ˆå™¨] å·²æ³¨å…¥ {len(cookies)} ä¸ª Cookie")
            else:
                logger.warning("[æµè§ˆå™¨] æœªé…ç½® Cookieï¼Œå¯èƒ½æ— æ³•è·å–ç¬”è®°æ•°æ®")

            page = await context.new_page()

            try:
                await page.goto(user_profile_url, wait_until="domcontentloaded", timeout=40000)
                # ç­‰å¾…é¡µé¢æ¸²æŸ“å®Œæˆ
                await page.wait_for_timeout(5000)

                # å‘ä¸‹æ»šåŠ¨ä»¥åŠ è½½æ›´å¤šç¬”è®°å¡ç‰‡
                for _ in range(3):
                    await page.evaluate("window.scrollBy(0, 800)")
                    await asyncio.sleep(1.5)

                # ===== ç­–ç•¥1ï¼šä» __INITIAL_STATE__ æå– SSR é¢„æ¸²æŸ“æ•°æ® =====
                try:
                    initial_state = await page.evaluate("""
                        () => {
                            try {
                                const state = window.__INITIAL_STATE__;
                                if (!state) return null;
                                // Playwright éœ€è¦è¿”å›å¯åºåˆ—åŒ–å¯¹è±¡ï¼Œè¿™é‡Œç›´æ¥æå–æ ¸å¿ƒå­—æ®µ
                                const result = {user: {}, notes: []};

                                // æå–ç”¨æˆ·ä¿¡æ¯
                                if (state.user && state.user.userPageData) {
                                    const u = state.user.userPageData;
                                    result.user = {nickname: u.basicInfo?.nickname || ''};
                                    // æå–ç”¨æˆ·å‘å¸ƒçš„ç¬”è®°
                                    const notes = u.notes || [];
                                    for (const n of notes) {
                                        if (n.id || n.noteId) {
                                            result.notes.push({
                                                note_id: n.id || n.noteId || '',
                                                title: n.displayTitle || n.title || '',
                                                xsec_token: n.xsecToken || '',
                                            });
                                        }
                                    }
                                }

                                // å°è¯•ä» feed è·¯å¾„è¯»å–
                                if (result.notes.length === 0 && state.feed) {
                                    const feeds = Object.values(state.feed);
                                    for (const feed of feeds) {
                                        if (feed && Array.isArray(feed.items)) {
                                            for (const item of feed.items) {
                                                const nc = item.noteCard || item;
                                                const nid = nc.id || nc.noteId || item.id || '';
                                                if (nid) {
                                                    result.notes.push({
                                                        note_id: nid,
                                                        title: nc.displayTitle || nc.title || '',
                                                        xsec_token: nc.xsecToken || '',
                                                    });
                                                }
                                            }
                                        }
                                    }
                                }

                                return result;
                            } catch(e) {
                                return {error: e.toString()};
                            }
                        }
                    """)

                    if initial_state and not initial_state.get("error"):
                        nickname = initial_state.get("user", {}).get("nickname", "")
                        if nickname and not page_user_name:
                            page_user_name = nickname

                        ssr_notes = initial_state.get("notes", [])
                        if ssr_notes:
                            logger.info(f"[SSR] ä» __INITIAL_STATE__ æå–åˆ° {len(ssr_notes)} æ¡ç¬”è®°")
                        for n in ssr_notes:
                            nid = n.get("note_id", "")
                            if nid and nid not in captured:
                                captured[nid] = n
                    elif initial_state and initial_state.get("error"):
                        logger.warning(f"[SSR] __INITIAL_STATE__ è§£æå¼‚å¸¸: {initial_state['error']}")
                    else:
                        logger.info("[SSR] __INITIAL_STATE__ ä¸ºç©ºæˆ–ä¸å­˜åœ¨")
                except Exception as e:
                    logger.warning(f"[SSR] æå– __INITIAL_STATE__ å¤±è´¥: {e}")

                # ===== ç­–ç•¥2ï¼šä» DOM é¡µé¢å…ƒç´ æå–ç¬”è®°é“¾æ¥ =====
                try:
                    dom_notes = await page.evaluate("""
                        () => {
                            const results = [];
                            // æŸ¥æ‰¾æ‰€æœ‰ç¬”è®°å¡ç‰‡é“¾æ¥ï¼ˆå¤šç§é€‰æ‹©å™¨å…¼å®¹ï¼‰
                            const selectors = [
                                'a[href*="/explore/"]',
                                'a[href*="/discovery/item/"]',
                                'a[href*="xsec_token"]',
                                'section.note-item a',
                                'div.note-item a',
                                '.feeds-container a[href*="/explore/"]',
                            ];
                            const seen = new Set();
                            for (const sel of selectors) {
                                const links = document.querySelectorAll(sel);
                                for (const a of links) {
                                    const href = a.href || a.getAttribute('href') || '';
                                    // ä» href æå– note_id
                                    const m = href.match(/\\/explore\\/([a-f0-9]+)/i)
                                             || href.match(/\\/discovery\\/item\\/([a-f0-9]+)/i);
                                    if (!m) continue;
                                    const noteId = m[1];
                                    if (seen.has(noteId)) continue;
                                    seen.add(noteId);

                                    // æå– xsec_token
                                    const tokenMatch = href.match(/xsec_token=([^&]+)/);
                                    const token = tokenMatch ? decodeURIComponent(tokenMatch[1]) : '';

                                    // æå–æ ‡é¢˜ï¼ˆä»å¡ç‰‡æ–‡å­—å…ƒç´ ï¼‰
                                    const titleEl = a.querySelector('.title, .note-title, span, footer span');
                                    const title = (titleEl ? titleEl.textContent : '') || a.textContent || '';

                                    results.push({
                                        note_id: noteId,
                                        title: title.trim().substring(0, 100),
                                        xsec_token: token,
                                    });
                                }
                            }
                            return results;
                        }
                    """)

                    if dom_notes:
                        logger.info(f"[DOM] ä»é¡µé¢ DOM æå–åˆ° {len(dom_notes)} æ¡ç¬”è®°é“¾æ¥")
                        for n in dom_notes:
                            nid = n.get("note_id", "")
                            token = n.get("xsec_token", "")
                            # è¡¥å……æˆ–æ›´æ–°ï¼ˆä¼˜å…ˆä¿ç•™æœ‰ token çš„ï¼‰
                            if nid and (nid not in captured or (token and not captured[nid].get("xsec_token"))):
                                captured[nid] = n
                    else:
                        logger.warning("[DOM] æœªä» DOM ä¸­æ‰¾åˆ°ä»»ä½•ç¬”è®°é“¾æ¥")

                except Exception as e:
                    logger.warning(f"[DOM] DOM æå–å¼‚å¸¸: {e}")

                # ===== ç­–ç•¥3ï¼šæ‰“å°é¡µé¢æˆªå›¾è·¯å¾„ä¾›äººå·¥æ’æŸ¥ =====
                if not captured:
                    debug_path = str(self.download_dir / f"debug_{self.user_id}.png")
                    try:
                        await page.screenshot(path=debug_path, full_page=True)
                        logger.warning(f"[è°ƒè¯•] æœªè·å–åˆ°ç¬”è®°ï¼Œå·²ä¿å­˜é¡µé¢æˆªå›¾: {debug_path}")
                    except Exception:
                        pass

                    # æ‰“å°é¡µé¢ URL å’Œæ ‡é¢˜ï¼Œç¡®è®¤æ˜¯å¦è·³è½¬
                    current_url = page.url
                    page_title = await page.title()
                    logger.info(f"[è°ƒè¯•] å½“å‰é¡µé¢ URL: {current_url}")
                    logger.info(f"[è°ƒè¯•] å½“å‰é¡µé¢æ ‡é¢˜: {page_title}")

            except Exception as e:
                logger.warning(f"[æµè§ˆå™¨] é¡µé¢åŠ è½½å¼‚å¸¸: {e}")
            finally:
                await browser.close()

        if page_user_name and not self.author_name:
            self.author_name = page_user_name

        # æ„å»ºæœ€ç»ˆç¬”è®°åˆ—è¡¨ï¼ˆå¸¦å®Œæ•´ URLï¼‰
        notes = []
        for note_data in captured.values():
            note_id = note_data["note_id"]
            token = note_data.get("xsec_token", "")
            if token:
                note_url = (
                    f"https://www.xiaohongshu.com/explore/{note_id}"
                    f"?xsec_token={token}&xsec_source=pc_user"
                )
            else:
                note_url = f"https://www.xiaohongshu.com/explore/{note_id}"
            notes.append({
                "note_id": note_id,
                "title": note_data.get("title", ""),
                "xsec_token": token,
                "note_url": note_url,
            })

        logger.info(f"[API] å…±æ•è· {len(notes)} ä¸ªç¬”è®°ï¼ˆåšä¸»: {self.user_id}ï¼‰")
        return notes

    async def check_and_download(self) -> int:
        """
        æ‰§è¡Œä¸€æ¬¡æ£€æŸ¥ï¼šæŠ“å–æœ€æ–°ç¬”è®° â†’ å¯¹æ¯” â†’ ä¸‹è½½æ–°å¸–ã€‚

        Returns:
            æœ¬æ¬¡å‘ç°å¹¶å¤„ç†çš„æ–°ç¬”è®°æ•°é‡
        """
        logger.info(f"[æ£€æŸ¥] å¼€å§‹æ£€æŸ¥åšä¸»: {self.user_id}")
        latest_notes = await self.fetch_latest_notes()

        if not latest_notes:
            logger.warning(f"[æ£€æŸ¥] æœªè·å–åˆ°ä»»ä½•ç¬”è®°ï¼Œå¯èƒ½æ˜¯ç™»å½•å¤±æ•ˆæˆ–åšä¸»æ— å†…å®¹")
            return 0

        # æ‰¾å‡ºæ–°ç¬”è®°ï¼ˆå½“å‰è®°å½•ä¸å«çš„ï¼‰
        new_notes = [n for n in latest_notes if n["note_id"] not in self._seen_ids]

        if not new_notes:
            logger.info(f"[æ£€æŸ¥] æ— æ–°ç¬”è®°ï¼ˆå·²çŸ¥ {len(self._seen_ids)} ç¯‡ï¼‰")
            return 0

        logger.info(f"[å‘ç°] åšä¸» {self.author_name or self.user_id} æœ‰ {len(new_notes)} ç¯‡æ–°ç¬”è®°ï¼")

        # é¦–æ¬¡è¿è¡Œæ—¶åªè®°å½• IDï¼Œä¸ä¸‹è½½ï¼ˆé˜²æ­¢æŠŠæ‰€æœ‰å†å²å¸–éƒ½ä¸‹è½½ä¸€éï¼‰
        if len(self._seen_ids) == 0:
            logger.info("[é¦–æ¬¡] é¦–æ¬¡è¿è¡Œï¼Œè®°å½•å½“å‰æ‰€æœ‰ç¬”è®° ID ä½œä¸ºåŸºçº¿ï¼Œä¸æ‰§è¡Œä¸‹è½½")
            for note in latest_notes:
                self._seen_ids.add(note["note_id"])
            self._save_seen_ids()
            logger.info(f"[é¦–æ¬¡] å·²è®°å½• {len(self._seen_ids)} ç¯‡ç¬”è®°ä¸ºåŸºçº¿ï¼Œåç»­æ£€æµ‹åˆ°æ–°å¸–æ‰ä¼šä¸‹è½½")
            return 0

        # ä¸‹è½½æ–°ç¬”è®°
        download_success = 0
        for idx, note in enumerate(new_notes, 1):
            note_id = note["note_id"]
            note_url = note["note_url"]
            title = note["title"]
            label = self.author_name or self.user_id

            logger.info(f"[ä¸‹è½½ {idx}/{len(new_notes)}] {title} â€” {note_url}")

            try:
                content = await self.downloader.download(note_url, save_text=True)
                if content:
                    logger.info(f"[ä¸‹è½½] âœ“ æˆåŠŸ: {title}")
                    download_success += 1

                    # Bark æ¨é€é€šçŸ¥
                    await self.notifier.push(
                        title=f"ğŸ“• {label} å‘å¸ƒæ–°å¸–",
                        body=f"ã€Š{title}ã€‹\n{note_url}",
                        url=note_url,
                        group="å°çº¢ä¹¦ç›‘æ§",
                    )
                else:
                    logger.warning(f"[ä¸‹è½½] âœ— å¤±è´¥: {title}")
            except Exception as e:
                logger.error(f"[ä¸‹è½½] å¼‚å¸¸: {title} â€” {e}")

            # æ— è®ºæˆåŠŸä¸å¦éƒ½è®°å½•ï¼ˆé¿å…é‡å¤å°è¯•ï¼‰
            self._seen_ids.add(note_id)

            # ä¸‹è½½é—´éš”ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            if idx < len(new_notes):
                await asyncio.sleep(3)

        self._save_seen_ids()
        logger.info(
            f"[å®Œæˆ] æœ¬è½®æ–°å¸–å¤„ç†å®Œæ¯•: å…± {len(new_notes)} ç¯‡ï¼ŒæˆåŠŸä¸‹è½½ {download_success} ç¯‡"
        )
        return len(new_notes)


# ==========================================
# å¤šåšä¸»è°ƒåº¦å™¨
# ==========================================
class XHSMonitorScheduler:
    """
    å¤šåšä¸»ç›‘æ§è°ƒåº¦å™¨ï¼Œæ”¯æŒå®šæ—¶è½®è¯¢ã€‚
    """

    def __init__(
            self,
            user_urls: List[str],
            interval: int = 600,
            download_dir: str = "downloads/xhs_monitor",
            cookie: str = "",
            bark_key: str = "",
            run_once: bool = False,
    ):
        """
        Args:
            user_urls: åšä¸»ä¸»é¡µ URL åˆ—è¡¨
            interval: è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
            download_dir: ä¸‹è½½æ ¹ç›®å½•
            cookie: å°çº¢ä¹¦ Cookie
            bark_key: Bark Key
            run_once: True åˆ™åªè¿è¡Œä¸€è½®åé€€å‡º
        """
        load_dotenv()

        self.user_urls = user_urls
        self.interval = interval
        self.run_once = run_once
        self.download_dir = Path(download_dir)

        # Cookie ä¼˜å…ˆçº§ï¼šå‚æ•° > .env
        self.cookie = cookie or os.getenv("XHS_COOKIE", "")

        # åˆ›å»ºç»Ÿä¸€çš„ä¸‹è½½å™¨ï¼ˆå¤ç”¨åŒä¸€ XHS sessionï¼‰
        self.downloader = XHSDownloader(
            cookie=self.cookie,
            download_dir=str(self.download_dir),
            skip_existing=True,
            download_image=True,
            download_video=True,
        )

        # åˆ›å»º Bark æ¨é€å™¨
        self.notifier = BarkNotifier(bark_key=bark_key)

        # å·²çŸ¥ç¬”è®°è®°å½•ç›®å½•
        seen_file_dir = self.download_dir / ".seen"
        seen_file_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–æ¯ä¸ªåšä¸»çš„ç›‘æ§å™¨
        self.monitors: List[XHSBloggerMonitor] = []
        for url in self.user_urls:
            if not USER_URL_PATTERN.search(url) and len(url) < 50:
                # å…¼å®¹ç›´æ¥ä¼ ç”¨æˆ· ID çš„æƒ…å†µ
                url = f"https://www.xiaohongshu.com/user/profile/{url}"
            monitor = XHSBloggerMonitor(
                user_url=url,
                download_dir=str(self.download_dir),
                downloader=self.downloader,
                notifier=self.notifier,
                seen_file_dir=seen_file_dir,
                cookie=self.cookie,
            )
            self.monitors.append(monitor)

    async def run_round(self):
        """æ‰§è¡Œä¸€è½®æ‰€æœ‰åšä¸»çš„æ£€æŸ¥"""
        if not self.monitors:
            logger.warning("[è°ƒåº¦] æ²¡æœ‰é…ç½®ä»»ä½•åšä¸»ï¼Œè¯·æ£€æŸ¥ --users å‚æ•°æˆ– XHS_MONITOR_USERS ç¯å¢ƒå˜é‡")
            return

        for monitor in self.monitors:
            try:
                await monitor.check_and_download()
            except Exception as e:
                logger.error(f"[è°ƒåº¦] åšä¸» {monitor.user_id} æ£€æŸ¥å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
            # å¤šåšä¸»ä¹‹é—´é€‚å½“é—´éš”
            if len(self.monitors) > 1:
                await asyncio.sleep(5)

    async def run(self):
        """å¯åŠ¨ç›‘æ§ä¸»å¾ªç¯"""
        self._print_banner()

        if self.run_once:
            logger.info("[è°ƒåº¦] å•æ¬¡æ¨¡å¼ï¼Œæ‰§è¡Œä¸€è½®åé€€å‡º")
            await self.run_round()
            logger.info("[è°ƒåº¦] å•æ¬¡æ£€æŸ¥å®Œæ¯•ï¼Œç¨‹åºé€€å‡º")
            return

        # æŒç»­å¾ªç¯
        round_num = 0
        while True:
            round_num += 1
            logger.info(f"\n{'=' * 60}")
            logger.info(f"  ç¬¬ {round_num} è½®æ£€æŸ¥  |  {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info(f"{'=' * 60}")

            await self.run_round()

            logger.info(f"[è°ƒåº¦] æœ¬è½®å®Œæˆï¼Œ{self.interval} ç§’åè¿›è¡Œä¸‹ä¸€è½®æ£€æŸ¥...")
            logger.info(
                f"[è°ƒåº¦] ä¸‹æ¬¡æ£€æŸ¥æ—¶é—´: {datetime.fromtimestamp(time.time() + self.interval).strftime('%H:%M:%S')}"
            )

            try:
                await asyncio.sleep(self.interval)
            except asyncio.CancelledError:
                logger.info("[è°ƒåº¦] ç›‘æ§å·²åœæ­¢")
                break

    def _print_banner(self):
        """æ‰“å°å¯åŠ¨ä¿¡æ¯"""
        print()
        print("=" * 60)
        print("  ğŸ” å°çº¢ä¹¦åšä¸»æ–°å¸–å®æ—¶ç›‘æ§")
        print("=" * 60)
        print(f"  ç›‘æ§åšä¸»æ•°: {len(self.monitors)}")
        for m in self.monitors:
            print(f"    - {m.user_id}")
        print(f"  æ£€æŸ¥é—´éš”: {self.interval} ç§’")
        print(f"  ä¸‹è½½ç›®å½•: {self.download_dir}")
        print(f"  Cookie:   {'âœ“ å·²é…ç½®' if self.cookie else 'âœ— æœªé…ç½®ï¼ˆå¯èƒ½å½±å“æ•ˆæœï¼‰'}")
        print(f"  Bark:     {'âœ“ å·²é…ç½®' if self.notifier.is_enabled() else 'âœ— æœªé…ç½®ï¼ˆä¸ä¼šæ¨é€é€šçŸ¥ï¼‰'}")
        print(f"  æ¨¡å¼:     {'å•æ¬¡' if self.run_once else 'æŒç»­å¾ªç¯'}")
        print("=" * 60)
        print()


# ==========================================
# å‘½ä»¤è¡Œå…¥å£
# ==========================================

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="å°çº¢ä¹¦åšä¸»æ–°å¸–å®æ—¶ç›‘æ§ â€” å‘ç°æ–°å¸–ç«‹å³ä¸‹è½½",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ä½¿ç”¨ .env é…ç½®çš„åšä¸»åˆ—è¡¨ï¼ˆXHS_MONITOR_USERSï¼‰
  python xhs_monitor.py

  # æ‰‹åŠ¨æŒ‡å®šå•ä¸ªåšä¸»
  python xhs_monitor.py --users "https://www.xiaohongshu.com/user/profile/xxx"

  # ç›‘æ§å¤šä¸ªåšä¸»ï¼ˆé€—å·åˆ†éš”ï¼‰
  python xhs_monitor.py --users "url1,url2,url3"

  # æ¯ 5 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
  python xhs_monitor.py --interval 300

  # ä»…æ£€æŸ¥ä¸€æ¬¡ï¼Œä¸å¾ªç¯
  python xhs_monitor.py --once

  # æŒ‡å®šä¸‹è½½ç›®å½•
  python xhs_monitor.py --download-dir "D:/å°çº¢ä¹¦ä¸‹è½½"
        """,
    )

    parser.add_argument(
        "--users",
        type=str,
        default="",
        help="åšä¸»ä¸»é¡µ URL åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œå¦‚ä¸ä¼ åˆ™è¯»å– .env çš„ XHS_MONITOR_USERS",
    )
    parser.add_argument(
        "--interval",
        type=int,
        default=0,
        help="æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰ï¼Œå¦‚ä¸ä¼ åˆ™è¯»å– .env çš„ XHS_MONITOR_INTERVALï¼ˆé»˜è®¤ 600 ç§’ï¼‰",
    )
    parser.add_argument(
        "--download-dir",
        type=str,
        default="",
        help="ä¸‹è½½ç›®å½•ï¼Œå¦‚ä¸ä¼ åˆ™è¯»å– .env çš„ XHS_MONITOR_DIRï¼ˆé»˜è®¤ downloads/xhs_monitorï¼‰",
    )
    parser.add_argument(
        "--once",
        action="store_true",
        help="åªæ£€æŸ¥ä¸€æ¬¡åé€€å‡ºï¼ˆä¸å¾ªç¯ï¼‰",
    )

    return parser.parse_args()


async def main():
    """ä¸»å‡½æ•°"""
    load_dotenv()
    args = parse_args()

    # è§£æåšä¸»åˆ—è¡¨ï¼šå‘½ä»¤è¡Œ > .env
    raw_users = args.users or os.getenv("XHS_MONITOR_USERS", "")
    user_urls = [u.strip() for u in raw_users.split(",") if u.strip()]

    # é™çº§ï¼šå¦‚æœæ²¡æœ‰é…ç½®ç›‘æ§åˆ—è¡¨ï¼Œå°è¯•è¯»å–å†å²é…ç½® XHS_TARGET_URL ä½œä¸ºå•åšä¸»
    if not user_urls:
        fallback = os.getenv("XHS_TARGET_URL", "").strip()
        if fallback:
            logger.info(f"[é…ç½®] æœªé…ç½® XHS_MONITOR_USERSï¼Œä½¿ç”¨ XHS_TARGET_URL ä½œä¸ºå¤‡é€‰: {fallback}")
            user_urls = [fallback]
        else:
            logger.error("[é…ç½®] è¯·é€šè¿‡ --users å‚æ•°æˆ– .env çš„ XHS_MONITOR_USERS æŒ‡å®šè¦ç›‘æ§çš„åšä¸»")
            sys.exit(1)

    # è§£æé—´éš”
    interval = args.interval or int(os.getenv("XHS_MONITOR_INTERVAL", "600"))

    # è§£æä¸‹è½½ç›®å½•
    download_dir = args.download_dir or os.getenv("XHS_MONITOR_DIR", "downloads/xhs_monitor")

    scheduler = XHSMonitorScheduler(
        user_urls=user_urls,
        interval=interval,
        download_dir=download_dir,
        run_once=args.once,
    )

    try:
        await scheduler.run()
    except KeyboardInterrupt:
        print("\n\n[ä¸­æ–­] ç¨‹åºå·²è¢«ç”¨æˆ·åœæ­¢ (Ctrl+C)")


if __name__ == "__main__":
    asyncio.run(main())
