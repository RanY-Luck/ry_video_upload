#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦å›¾æ–‡ç¬”è®°æ‰¹é‡ä¸Šä¼ å·¥å…·

åŠŸèƒ½ï¼š
  - æ‰«æ downloads/xhs_monitor ç›®å½•ï¼ˆxhs_monitor.py çš„ä¸‹è½½è¾“å‡ºï¼‰
  - è¯»å–æ¯ç¯‡ç¬”è®°çš„å›¾ç‰‡ + txt æ–‡æ¡ˆ
  - é€šè¿‡ Playwright æ¨¡æ‹Ÿæµè§ˆå™¨ï¼Œåœ¨ creator.xiaohongshu.com å‘å¸ƒå›¾æ–‡ç¬”è®°
  - ç»´æŠ¤ä¸Šä¼ å†å²è®°å½•ï¼Œé¿å…é‡å¤ä¸Šä¼ 
  - æ”¯æŒ --dry-run æ¨¡å¼ï¼ˆåªæ‰«æï¼Œä¸å®é™…ä¸Šä¼ ï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
  # é»˜è®¤æ¨¡å¼ï¼ˆæŒç»­ç›‘æ§ä¸Šä¼ ï¼‰
  python xhs_upload.py

  # å•æ¬¡è¿è¡Œåé€€å‡º
  python xhs_upload.py --once

  # è¯•è¿è¡Œï¼ˆåªæ‰«ææ‰“å°ï¼Œä¸ä¸Šä¼ ï¼‰
  python xhs_upload.py --dry-run

  # æŒ‡å®šä¸‹è½½ç›®å½•
  python xhs_upload.py --dir downloads/xhs_monitor

  # æŒ‡å®šé—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 300 ç§’
  python xhs_upload.py --interval 600
"""

import argparse
import asyncio
import json
import logging
import os
import re
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

try:
    import dashscope
    from dashscope import Generation
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False

try:
    import requests as _requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

from dotenv import load_dotenv

# ==========================================
# æ—¥å¿—é…ç½®
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.StreamHandler(sys.stdout),
    ],
)
logger = logging.getLogger("xhs_upload")

# ==========================================
# å¸¸é‡
# ==========================================
CREATOR_URL = "https://creator.xiaohongshu.com/publish/publish"
LOGIN_URL = "https://creator.xiaohongshu.com"

# å›¾ç‰‡æ”¯æŒçš„æ‰©å±•å
IMAGE_EXTS = {".jpg", ".jpeg", ".png", ".webp", ".gif"}

# è§†é¢‘æ”¯æŒçš„æ‰©å±•å
VIDEO_EXTS = {".mp4", ".mov", ".avi", ".flv", ".mkv", ".webm"}

# ä¸Šä¼ è®°å½•æ–‡ä»¶
HISTORY_FILE = Path("logs/xhs_upload_history.txt")

# ä¸¤æ¬¡ä¸Šä¼ ä¹‹é—´ä¼‘çœ æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé¿å…é£æ§
UPLOAD_SLEEP = 30

# AI æ¶¦è‰²æ¨¡å‹
AI_MODEL = "qwen-turbo"

# Bark æœåŠ¡å™¨
BARK_SERVER = "https://api.day.app"


# ==========================================
# AI æ¶¦è‰²
# ==========================================
class XHSAIPolisher:
    """
    ä½¿ç”¨é˜¿é‡Œç™¾ç‚¼ qwen-turbo å¯¹å°çº¢ä¹¦ç¬”è®°æ ‡é¢˜å’Œæ­£æ–‡è¿›è¡Œæ¶¦è‰²äºŒåˆ›ã€‚
    å¤±è´¥æ—¶å®‰å…¨é™çº§ï¼Œè¿”å›åŸå§‹æ–‡æ¡ˆï¼Œä¸é˜»æ–­ä¸Šä¼ æµç¨‹ã€‚
    """

    def __init__(self):
        self.api_key = os.getenv("DASHSCOPE_API_KEY", "")
        self.available = DASHSCOPE_AVAILABLE and bool(self.api_key)
        if self.available:
            dashscope.api_key = self.api_key

    def polish(self, title: str, description: str) -> Dict[str, str]:
        """
        æ¶¦è‰²æ ‡é¢˜å’Œæè¿°ã€‚

        Args:
            title:       åŸå§‹æ ‡é¢˜
            description: åŸå§‹æ­£æ–‡

        Returns:
            {"title": æ¶¦è‰²åæ ‡é¢˜, "description": æ¶¦è‰²åæ­£æ–‡}
            å¤±è´¥æ—¶è¿”å›åŸå§‹å€¼ã€‚
        """
        if not self.available:
            if not DASHSCOPE_AVAILABLE:
                logger.warning("[AIæ¶¦è‰²] dashscope æœªå®‰è£…ï¼Œè·³è¿‡æ¶¦è‰²ï¼ˆpip install dashscopeï¼‰")
            else:
                logger.warning("[AIæ¶¦è‰²] æœªé…ç½® DASHSCOPE_API_KEYï¼Œè·³è¿‡æ¶¦è‰²")
            return {"title": title, "description": description}

        max_retries = 3
        for attempt in range(1, max_retries + 1):
            try:
                logger.info(f"[AIæ¶¦è‰²] æ­£åœ¨æ¶¦è‰²: {title[:30]}ï¼ˆç¬¬ {attempt}/{max_retries} æ¬¡ï¼‰")

                prompt = f"""è¯·å¯¹ä»¥ä¸‹å°çº¢ä¹¦ç¬”è®°è¿›è¡Œæ¶¦è‰²äºŒåˆ›ï¼Œä¿ç•™åŸæ„ï¼Œé£æ ¼æ›´æ´»æ³¼è‡ªç„¶ï¼Œé€‚åˆå°çº¢ä¹¦å¹³å°ã€‚
è¦æ±‚ï¼š
- æ ‡é¢˜ï¼šæ§åˆ¶åœ¨ 20 å­—ä»¥å†…ï¼ŒåŠ å…¥æƒ…æ„Ÿé’©å­ï¼Œå¯ç”¨ 1-2 ä¸ª emoji
- æ­£æ–‡ï¼šä¿ç•™åŸæœ‰æ ¸å¿ƒä¿¡æ¯ï¼Œè¯­æ°”æ›´äº²åˆ‡ï¼Œé€‚å½“åŠ  emojiï¼Œç»“å°¾å¯è¿½åŠ  3~5 ä¸ªè¯é¢˜æ ‡ç­¾ï¼ˆ#è¯é¢˜ æ ¼å¼ï¼‰
- ä¸¥æ ¼æŒ‰ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ï¼š
{{
  "title": "æ¶¦è‰²åçš„æ ‡é¢˜",
  "description": "æ¶¦è‰²åçš„æ­£æ–‡"
}}

åŸå§‹æ ‡é¢˜ï¼š{title}
åŸå§‹æ­£æ–‡ï¼š{description if description else 'ï¼ˆæ— æ­£æ–‡ï¼‰'}"""

                response = Generation.call(
                    model=AI_MODEL,
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä½æ‹¥æœ‰ 5 å¹´ç»éªŒçš„å°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆä¸“å®¶ï¼Œæ“…é•¿æŠŠæ™®é€šæ–‡æ¡ˆæ”¹å†™æˆé«˜äº’åŠ¨ç‡ç¬”è®°ã€‚",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    result_format="message",
                )

                if response.status_code != 200:
                    raise ValueError(f"API è¿”å›å¼‚å¸¸çŠ¶æ€ç : {response.status_code}, ä¿¡æ¯: {response.message}")

                raw = response.output.choices[0].message.content.strip()

                # æå– JSONï¼ˆå…¼å®¹ AI åœ¨å›ç­”å‰/åå¤šä½™æ–‡å­—çš„æƒ…å†µï¼‰
                json_match = re.search(r'\{[\s\S]*\}', raw)
                if not json_match:
                    raise ValueError(f"æœªæ‰¾åˆ° JSON å†…å®¹ï¼ŒåŸå§‹è¾“å‡º: {raw[:200]}")

                result = json.loads(json_match.group())
                polished_title = result.get("title", "").strip() or title
                polished_desc = result.get("description", "").strip() or description

                logger.info(f"[AIæ¶¦è‰²] âœ… æ¶¦è‰²å®Œæˆ")
                logger.info(f"[AIæ¶¦è‰²] æ ‡é¢˜: {title[:20]} â†’ {polished_title[:30]}")
                return {"title": polished_title, "description": polished_desc}

            except Exception as e:
                logger.warning(f"[AIæ¶¦è‰²] âš ï¸ ç¬¬ {attempt} æ¬¡å¤±è´¥: {e}")
                if attempt < max_retries:
                    time.sleep(2)

        logger.error("[AIæ¶¦è‰²] âŒ æ¶¦è‰²æœ€ç»ˆå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æ¡ˆç»§ç»­ä¸Šä¼ ")
        return {"title": title, "description": description}


# ==========================================
# Bark æ¨é€
# ==========================================
def bark_notify_success(note_title: str):
    """
    ä¸Šä¼ æˆåŠŸåæ¨é€ Bark é€šçŸ¥ã€‚
    å®‰å…¨è°ƒç”¨ï¼Œå¤±è´¥æ—¶ä»…æ‰“å°è­¦å‘Šï¼Œä¸å½±å“ä¸»æµç¨‹ã€‚

    Args:
        note_title: å·²å‘å¸ƒçš„ç¬”è®°æ ‡é¢˜
    """
    if not REQUESTS_AVAILABLE:
        logger.warning("[Bark] requests æœªå®‰è£…ï¼Œè·³è¿‡æ¨é€")
        return

    bark_key = os.getenv("BARK_KEY", "").strip()
    if not bark_key:
        logger.warning("[Bark] æœªé…ç½® BARK_KEYï¼Œè·³è¿‡æ¨é€")
        return

    try:
        title_encoded = "ğŸ“¤ å°çº¢ä¹¦ç¬”è®°å·²å‘å¸ƒ"
        body = note_title[:50]  # Bark URL å‚æ•°ï¼Œæ§åˆ¶é•¿åº¦
        url = f"{BARK_SERVER}/{bark_key}/{title_encoded}/{body}"
        params = {
            "group": "å°çº¢ä¹¦ä¸Šä¼ ",
            "sound": "fanfare",
            "icon": "https://api.iconify.design/mdi:note-check-outline.svg",
        }
        resp = _requests.get(url, params=params, timeout=10)
        resp.raise_for_status()
        result = resp.json()
        if result.get("code") == 200:
            logger.info(f"[Bark] âœ… æ¨é€æˆåŠŸ: {note_title[:20]}")
        else:
            logger.warning(f"[Bark] æ¨é€è¿”å›: {result}")
    except Exception as e:
        logger.warning(f"[Bark] æ¨é€å¤±è´¥ï¼ˆä¸å½±å“ä¸Šä¼ ï¼‰: {e}")


# ==========================================
# å†å²è®°å½•ç®¡ç†
# ==========================================
class UploadHistory:
    """ç®¡ç†å·²ä¸Šä¼ ç¬”è®°çš„è®°å½•ï¼Œé¿å…é‡å¤ä¸Šä¼ """

    def __init__(self, history_file: Path = HISTORY_FILE):
        self.history_file = history_file
        self._uploaded: set = self._load()

    def _load(self) -> set:
        if not self.history_file.exists():
            return set()
        try:
            with open(self.history_file, "r", encoding="utf-8") as f:
                return {line.strip() for line in f if line.strip()}
        except Exception as e:
            logger.warning(f"[å†å²] è¯»å–è®°å½•å¤±è´¥: {e}")
            return set()

    def has(self, note_id: str) -> bool:
        return note_id in self._uploaded

    def add(self, note_id: str):
        self._uploaded.add(note_id)
        try:
            self.history_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.history_file, "a", encoding="utf-8") as f:
                f.write(f"{note_id}\n")
        except Exception as e:
            logger.error(f"[å†å²] ä¿å­˜è®°å½•å¤±è´¥: {e}")

    def count(self) -> int:
        return len(self._uploaded)


# ==========================================
# ç¬”è®°å†…å®¹è§£æ
# ==========================================
def parse_note_folder(folder: Path) -> Optional[Dict]:
    """
    è§£æä¸‹è½½çš„ç¬”è®°æ–‡ä»¶å¤¹ï¼Œæå–æ ‡é¢˜ã€æè¿°ã€å›¾ç‰‡/è§†é¢‘è·¯å¾„ã€‚
    è‡ªåŠ¨åˆ¤æ–­ç¬”è®°ç±»å‹ï¼šå« mp4 åˆ™ä¸ºè§†é¢‘ç¬”è®°ï¼Œå¦åˆ™ä¸ºå›¾æ–‡ç¬”è®°ã€‚

    ç›®å½•ç»“æ„ï¼ˆç”± xhs_monitor.py ç”Ÿæˆï¼‰ï¼š
      {note_id}_{æ ‡é¢˜}/
        {æ ‡é¢˜}.txt
        {æ ‡é¢˜}_0.jpg       â† å›¾æ–‡ç¬”è®°
        or
        {æ ‡é¢˜}_0.mp4       â† è§†é¢‘ç¬”è®°

    è¿”å›å­—æ®µï¼š
      note_type: "video" | "image"
      videos:    è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆè§†é¢‘ç¬”è®°æ—¶æœ‰æ•ˆï¼‰
      images:    å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå›¾æ–‡ç¬”è®°æ—¶æœ‰æ•ˆï¼‰
    """
    # ä»æ–‡ä»¶å¤¹åæå– note_idï¼ˆæ ¼å¼ï¼š{note_id}_{æ ‡é¢˜}ï¼‰
    folder_name = folder.name
    parts = folder_name.split("_", 1)
    note_id = parts[0] if len(parts[0]) >= 16 else folder_name  # XHS note_id é€šå¸¸ 24 å­—ç¬¦
    # æ›´ç²¾ç¡®åœ°ä»çœŸå® ID æ ¼å¼æå–
    id_match = re.match(r"^([a-f0-9]{24})", folder_name, re.IGNORECASE)
    if id_match:
        note_id = id_match.group(1)
    else:
        note_id = folder_name  # å…œåº•ä½¿ç”¨æ–‡ä»¶å¤¹åä½œä¸ºå”¯ä¸€ ID

    # æŸ¥æ‰¾ txt æ–‡æ¡ˆæ–‡ä»¶
    txt_files = list(folder.glob("*.txt"))
    if not txt_files:
        logger.debug(f"[æ‰«æ] {folder.name}: æ—  txt æ–‡æ¡ˆæ–‡ä»¶ï¼Œè·³è¿‡")
        return None

    txt_file = txt_files[0]

    # è§£æ txt æ–‡ä»¶
    title = ""
    author = ""
    description = ""
    try:
        content = txt_file.read_text(encoding="utf-8")
        lines = content.splitlines()
        meta_done = False
        desc_lines = []

        for line in lines:
            if not meta_done:
                if line.startswith("æ ‡é¢˜:") or line.startswith("æ ‡é¢˜ï¼š"):
                    title = line.split(":", 1)[-1].strip() if ":" in line else line.split("ï¼š", 1)[-1].strip()
                elif line.startswith("ä½œè€…:") or line.startswith("ä½œè€…ï¼š"):
                    author = line.split(":", 1)[-1].strip() if ":" in line else line.split("ï¼š", 1)[-1].strip()
                elif line.startswith("ID:"):
                    # ä» txt é‡Œè¯»å–çœŸå® note_id
                    real_id = line.split(":", 1)[-1].strip()
                    if real_id:
                        note_id = real_id
                elif line == "" and title:
                    # é‡åˆ°ç¬¬ä¸€ä¸ªç©ºè¡Œï¼ˆä¸”å·²è§£æåˆ°æ ‡é¢˜ï¼‰åï¼Œåç»­å†…å®¹ä¸ºæ­£æ–‡
                    meta_done = True
            else:
                desc_lines.append(line)

        description = "\n".join(desc_lines).strip()
    except Exception as e:
        logger.warning(f"[è§£æ] è¯»å– {txt_file} å¤±è´¥: {e}")
        title = folder_name
        description = ""

    if not title:
        title = folder_name

    # æ”¶é›†è§†é¢‘æ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰
    video_files = sorted(
        [f for f in folder.iterdir() if f.suffix.lower() in VIDEO_EXTS],
        key=lambda x: x.name,
    )

    # æ”¶é›†å›¾ç‰‡æ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰
    image_files = sorted(
        [f for f in folder.iterdir() if f.suffix.lower() in IMAGE_EXTS],
        key=lambda x: x.name,
    )

    # åˆ¤æ–­ç¬”è®°ç±»å‹ï¼šæœ‰è§†é¢‘ä¼˜å…ˆä½œä¸ºè§†é¢‘ç¬”è®°
    if video_files:
        note_type = "video"
        logger.debug(f"[æ‰«æ] {folder.name}: è§†é¢‘ç¬”è®°ï¼ˆ{len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶ï¼‰")
    elif image_files:
        note_type = "image"
        logger.debug(f"[æ‰«æ] {folder.name}: å›¾æ–‡ç¬”è®°ï¼ˆ{len(image_files)} å¼ å›¾ç‰‡ï¼‰")
    else:
        logger.debug(f"[æ‰«æ] {folder.name}: æ— å›¾ç‰‡/è§†é¢‘æ–‡ä»¶ï¼Œè·³è¿‡")
        return None

    return {
        "note_id": note_id,
        "note_type": note_type,    # "video" æˆ– "image"
        "folder": folder,
        "title": title,
        "author": author,
        "description": description,
        "images": image_files,     # å›¾æ–‡ç¬”è®°æ—¶ä½¿ç”¨
        "videos": video_files,     # è§†é¢‘ç¬”è®°æ—¶ä½¿ç”¨
    }


# ==========================================
# ç›®å½•æ‰«æå™¨
# ==========================================
class NoteScanner:
    """æ‰«æ xhs_monitor ä¸‹è½½ç›®å½•ï¼Œæ”¶é›†å¾…ä¸Šä¼ çš„ç¬”è®°"""

    def __init__(self, download_dir: str, history: UploadHistory):
        self.download_dir = Path(download_dir)
        self.history = history

    def scan(self) -> List[Dict]:
        """
        æ‰«æå¹¶è¿”å›æ‰€æœ‰å¾…ä¸Šä¼ çš„ç¬”è®°åˆ—è¡¨ã€‚

        ç›®å½•ç»“æ„ï¼š
          download_dir/
            {ä½œè€…å}/
              {note_id}_{æ ‡é¢˜}/   â† è¿™ä¸€å±‚æ‰æ˜¯ç¬”è®°æ–‡ä»¶å¤¹
        """
        if not self.download_dir.exists():
            logger.warning(f"[æ‰«æ] ä¸‹è½½ç›®å½•ä¸å­˜åœ¨: {self.download_dir}")
            return []

        pending = []

        # éå† {ä½œè€…å} å­ç›®å½•
        for author_dir in sorted(self.download_dir.iterdir()):
            if not author_dir.is_dir():
                continue
            # è·³è¿‡éšè—ç›®å½•ï¼ˆå¦‚ .seenï¼‰
            if author_dir.name.startswith("."):
                continue

            # éå† {note_id}_{æ ‡é¢˜} å­ç›®å½•
            for note_folder in sorted(author_dir.iterdir()):
                if not note_folder.is_dir():
                    continue

                note = parse_note_folder(note_folder)
                if note is None:
                    continue

                if self.history.has(note["note_id"]):
                    logger.debug(f"[æ‰«æ] è·³è¿‡å·²ä¸Šä¼ : {note['note_id']} â€” {note['title'][:20]}")
                    continue

                pending.append(note)

        logger.info(f"[æ‰«æ] å‘ç° {len(pending)} ç¯‡å¾…ä¸Šä¼ ç¬”è®°")
        return pending


# ==========================================
# å°çº¢ä¹¦ä¸Šä¼ å™¨ï¼ˆPlaywrightï¼‰
# ==========================================
class XHSUploader:
    """
    ä½¿ç”¨ Playwright æ¨¡æ‹Ÿæµè§ˆå™¨ï¼Œåœ¨ creator.xiaohongshu.com å‘å¸ƒå›¾æ–‡ç¬”è®°ã€‚
    """

    def __init__(self, cookie: str = "", account_file: str = ""):
        self.cookie = cookie or os.getenv("XHS_COOKIE", "")
        self.account_file = Path(account_file) if account_file else None
        # ä» .env è¯»å–è´¦å·æ–‡ä»¶è·¯å¾„
        if not self.account_file:
            env_account = os.getenv("XHS_UPLOAD_ACCOUNT", "")
            if env_account:
                self.account_file = Path(env_account)

    def _parse_cookie_str(self, cookie_str: str) -> List[Dict]:
        """å°† cookie å­—ç¬¦ä¸²è§£æä¸º Playwright cookie æ ¼å¼"""
        cookies = []
        for item in cookie_str.split(";"):
            item = item.strip()
            if "=" not in item:
                continue
            name, value = item.split("=", 1)
            cookies.append({
                "name": name.strip(),
                "value": value.strip(),
                "domain": ".xiaohongshu.com",
                "path": "/",
            })
        return cookies

    async def _inject_cookies(self, context):
        """å‘æµè§ˆå™¨ä¸Šä¸‹æ–‡æ³¨å…¥ Cookie"""
        injected = 0

        # ä¼˜å…ˆè¯»å–è´¦å· JSON æ–‡ä»¶ï¼ˆPlaywright æ ¼å¼ï¼‰
        if self.account_file and self.account_file.exists():
            try:
                with open(self.account_file, "r", encoding="utf-8") as f:
                    saved = json.load(f)
                cookies = saved if isinstance(saved, list) else saved.get("cookies", [])
                if cookies:
                    await context.add_cookies(cookies)
                    injected = len(cookies)
                    logger.info(f"[ç™»å½•] ä»è´¦å·æ–‡ä»¶æ³¨å…¥ {injected} ä¸ª Cookie: {self.account_file}")
                    return injected
            except Exception as e:
                logger.warning(f"[ç™»å½•] è¯»å–è´¦å·æ–‡ä»¶å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨ XHS_COOKIE å­—ç¬¦ä¸²")

        # ä½¿ç”¨ XHS_COOKIE å­—ç¬¦ä¸²
        if self.cookie:
            cookies = self._parse_cookie_str(self.cookie)
            if cookies:
                await context.add_cookies(cookies)
                injected = len(cookies)
                logger.info(f"[ç™»å½•] ä» XHS_COOKIE æ³¨å…¥ {injected} ä¸ª Cookie")

        return injected

    async def _wait_for_login(self, page) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å·²ç™»å½•ã€‚
        å¦‚æœæœªç™»å½•ï¼Œç­‰å¾…ç”¨æˆ·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨æ‰«ç ï¼Œæœ€å¤šç­‰å¾… 120 ç§’ã€‚
        """
        # è®¿é—®åˆ›ä½œè€…ä¸»é¡µ
        await page.goto(LOGIN_URL, wait_until="domcontentloaded", timeout=30000)
        await page.wait_for_timeout(3000)

        # åˆ¤æ–­æ˜¯å¦éœ€è¦ç™»å½•ï¼ˆURL è·³è½¬åˆ°ç™»å½•é¡µæˆ–å‡ºç°äºŒç»´ç ï¼‰
        current_url = page.url
        if "creator.xiaohongshu.com" in current_url and "login" not in current_url:
            logger.info("[ç™»å½•] âœ“ Cookie æœ‰æ•ˆï¼Œå·²ç™»å½•")
            return True

        # ç­‰å¾…æ‰‹åŠ¨æ‰«ç 
        logger.warning("[ç™»å½•] Cookie æ— æ•ˆæˆ–æœªç™»å½•ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­æ‰«ç ç™»å½•...")
        logger.warning("[ç™»å½•] ç­‰å¾…æœ€å¤š 120 ç§’...")

        for i in range(120):
            await asyncio.sleep(1)
            url = page.url
            if "creator.xiaohongshu.com" in url and "login" not in url:
                logger.info("[ç™»å½•] âœ“ æ‰«ç ç™»å½•æˆåŠŸï¼")
                return True

        logger.error("[ç™»å½•] âœ— ç™»å½•è¶…æ—¶")
        return False

    async def _save_account(self, context):
        """ç™»å½•æˆåŠŸåä¿å­˜ Cookie åˆ°è´¦å·æ–‡ä»¶"""
        if not self.account_file:
            return
        try:
            self.account_file.parent.mkdir(parents=True, exist_ok=True)
            cookies = await context.cookies()
            with open(self.account_file, "w", encoding="utf-8") as f:
                json.dump(cookies, f, ensure_ascii=False, indent=2)
            logger.info(f"[ç™»å½•] Cookie å·²ä¿å­˜åˆ°: {self.account_file}")
        except Exception as e:
            logger.warning(f"[ç™»å½•] ä¿å­˜ Cookie å¤±è´¥: {e}")

    async def upload_note(
        self,
        page,
        title: str,
        description: str,
        image_paths: List[Path],
        note_type: str = "image",
        video_paths: Optional[List[Path]] = None,
    ) -> bool:
        """
        åœ¨ creator.xiaohongshu.com å‘å¸ƒä¸€ç¯‡ç¬”è®°ã€‚

        note_type = "image" â†’ ä¸Šä¼ å›¾æ–‡ï¼ˆimage_paths ä¸ºå›¾ç‰‡åˆ—è¡¨ï¼‰
        note_type = "video" â†’ ä¸Šä¼ è§†é¢‘ï¼ˆvideo_paths[0] ä¸ºè§†é¢‘æ–‡ä»¶ï¼‰

        DOM ç»“æ„ï¼ˆé€šè¿‡å®é™…é¡µé¢æ£€æŸ¥ç¡®è®¤ 2026-02-27ï¼‰ï¼š
          - è§†é¢‘ tab:    div.creator-tabï¼ˆå«æ–‡å­—"ä¸Šä¼ è§†é¢‘"ï¼‰
          - å›¾æ–‡ tab:    div.creator-tabï¼ˆå«æ–‡å­—"ä¸Šä¼ å›¾æ–‡"ï¼‰
          - å›¾ç‰‡ input:  input.upload-inputï¼ˆå›¾æ–‡æ¨¡å¼ accept=".jpg,.jpeg,.png,.webp", multiple=trueï¼‰
          - è§†é¢‘ input:  input.upload-inputï¼ˆè§†é¢‘æ¨¡å¼ accept=".mp4,.mov,.flv..." multiple=falseï¼‰
          - æ ‡é¢˜/æ­£æ–‡:   ä¸Šä¼ åª’ä½“ååŠ¨æ€æ¸²æŸ“
          - å‘å¸ƒæŒ‰é’®:    button å«æ–‡å­—"å‘å¸ƒ"

        Returns:
            True è¡¨ç¤ºå‘å¸ƒæˆåŠŸ
        """
        video_paths = video_paths or []
        type_label = "è§†é¢‘" if note_type == "video" else "å›¾æ–‡"
        logger.info(f"[ä¸Šä¼ ] å¼€å§‹å‘å¸ƒ [{type_label}]: {title[:30]}")
        if note_type == "video":
            logger.info(f"[ä¸Šä¼ ] è§†é¢‘æ–‡ä»¶: {len(video_paths)} ä¸ª")
        else:
            logger.info(f"[ä¸Šä¼ ] å›¾ç‰‡æ•°é‡: {len(image_paths)}")


        try:
            # â”€â”€ æ­¥éª¤ 1ï¼šæ‰“å¼€å‘å¸ƒé¡µï¼Œç­‰å¾…é¡µé¢å®Œæ•´æ¸²æŸ“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            await page.goto(CREATOR_URL, wait_until="domcontentloaded", timeout=30000)
            # ç­‰å¾… creator-tab å‡ºç°ï¼ˆç¡®è®¤é¡µé¢ JS å·²æ¸²æŸ“ï¼‰
            try:
                await page.wait_for_selector(".creator-tab", timeout=10000)
                logger.info("[ä¸Šä¼ ] âœ“ é¡µé¢å·²æ¸²æŸ“ï¼ˆæ£€æµ‹åˆ° .creator-tabï¼‰")
            except Exception:
                logger.warning("[ä¸Šä¼ ] .creator-tab è¶…æ—¶ï¼Œç»§ç»­ç­‰å¾… 3 ç§’")
                await page.wait_for_timeout(3000)

            # â”€â”€ æ­¥éª¤ 2ï¼šåˆ‡æ¢åˆ°å¯¹åº” tabï¼ˆç”¨ JS æ‰¾å¯è§å…ƒç´ å evaluate clickï¼Œé¿å…è§†å£å¤–è¶…æ—¶ï¼‰
            # å®æµ‹ï¼š4ä¸ª .creator-tab ä¸­æœ‰1ä¸ªéšè—ï¼ˆBoundingRect åœ¨è´Ÿåæ ‡åŒºï¼‰ï¼Œéœ€è¿‡æ»¤
            tab_keyword = "å›¾æ–‡" if note_type == "image" else "è§†é¢‘"
            switched = False

            # ç”¨ JS æ‰¾åˆ°å¯è§ä¸”å«å…³é”®å­—çš„ tabï¼Œç›´æ¥åœ¨é¡µé¢å†…ç‚¹å‡»ï¼ˆç»•è¿‡ Playwright çš„è§†å£æ£€æµ‹ï¼‰
            clicked = await page.evaluate(f"""
                () => {{
                    const tabs = Array.from(document.querySelectorAll('.creator-tab'));
                    for (const tab of tabs) {{
                        const rect = tab.getBoundingClientRect();
                        const visible = rect.width > 0 && rect.height > 0 && rect.x >= 0 && rect.y >= 0;
                        if (visible && tab.textContent.includes('{tab_keyword}')) {{
                            tab.click();
                            return tab.textContent.trim();
                        }}
                    }}
                    return null;
                }}
            """)
            if clicked:
                await page.wait_for_timeout(1500)
                logger.info(f"[ä¸Šä¼ ] âœ“ å·²é€šè¿‡ JS ç‚¹å‡» tab: '{clicked}'")
                switched = True
            else:
                logger.warning(f"[ä¸Šä¼ ] JS æ–¹å¼æœªæ‰¾åˆ°å¯è§çš„'{tab_keyword}' tabï¼Œæˆªå›¾åç»§ç»­")
                await _save_debug_screenshot(page, f"{title}_no_tab")

            # â”€â”€ æ­¥éª¤ 3ï¼šç­‰å¾… input å°±ç»ªï¼Œä¸Šä¼ åª’ä½“æ–‡ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            upload_input = None

            if note_type == "video":
                # è§†é¢‘æ¨¡å¼ï¼šinput.upload-inputï¼Œaccept å« mp4
                try:
                    await page.wait_for_selector('input.upload-input[accept*="mp4"]', timeout=8000)
                    upload_input = await page.query_selector('input.upload-input[accept*="mp4"]')
                    logger.info("[ä¸Šä¼ ] âœ“ æ‰¾åˆ°è§†é¢‘ file input")
                except Exception:
                    upload_input = await page.query_selector("input.upload-input")
                    if upload_input:
                        logger.info("[ä¸Šä¼ ] âœ“ æ‰¾åˆ° upload-inputï¼ˆé™çº§ï¼‰")

                if not upload_input:
                    logger.error("[ä¸Šä¼ ] âœ— æœªæ‰¾åˆ°è§†é¢‘ä¸Šä¼  input")
                    await _save_debug_screenshot(page, f"{title}_no_input")
                    return False

                vfile = next((p for p in video_paths if p.exists()), None)
                if not vfile:
                    logger.error("[ä¸Šä¼ ] âœ— è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
                    return False
                logger.info(f"[ä¸Šä¼ ] æ­£åœ¨ä¸Šä¼ è§†é¢‘: {vfile.name}")
                await upload_input.set_input_files(str(vfile.absolute()))

            else:
                # å›¾æ–‡æ¨¡å¼ï¼šinput.upload-inputï¼Œaccept å« jpgï¼Œmultiple=true
                try:
                    await page.wait_for_selector('input.upload-input[accept*="jpg"]', timeout=8000)
                    upload_input = await page.query_selector('input.upload-input[accept*="jpg"]')
                    logger.info("[ä¸Šä¼ ] âœ“ æ‰¾åˆ°å›¾æ–‡ file input")
                except Exception:
                    upload_input = await page.query_selector("input.upload-input")
                    if upload_input:
                        logger.info("[ä¸Šä¼ ] âœ“ æ‰¾åˆ° upload-inputï¼ˆé™çº§ï¼‰")

                if not upload_input:
                    logger.error("[ä¸Šä¼ ] âœ— æœªæ‰¾åˆ°å›¾ç‰‡ä¸Šä¼  input")
                    await _save_debug_screenshot(page, f"{title}_no_input")
                    return False

                file_list = [str(p.absolute()) for p in image_paths if p.exists()]
                missing = [str(p) for p in image_paths if not p.exists()]
                if missing:
                    logger.warning(f"[ä¸Šä¼ ] ä»¥ä¸‹å›¾ç‰‡ä¸å­˜åœ¨ï¼Œè·³è¿‡: {missing}")
                if not file_list:
                    logger.error("[ä¸Šä¼ ] âœ— æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶å‡ä¸å­˜åœ¨")
                    return False
                logger.info(f"[ä¸Šä¼ ] æ­£åœ¨ä¸Šä¼  {len(file_list)} å¼ å›¾ç‰‡: {[Path(f).name for f in file_list]}")
                await upload_input.set_input_files(file_list)

            # â”€â”€ æ­¥éª¤ 4ï¼šç­‰å¾…ç¼–è¾‘åŒºæ¸²æŸ“ï¼ˆä¸Šä¼ ååŠ¨æ€æ³¨å…¥ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # å®æµ‹ï¼šæ ‡é¢˜æ¡†ä¸º input.d-textï¼Œæ­£æ–‡ä¸º div.tiptap.ProseMirror
            logger.info("[ä¸Šä¼ ] ç­‰å¾…ç¼–è¾‘åŒºæ¸²æŸ“...")
            try:
                await page.wait_for_selector(
                    'input.d-text, input[placeholder*="å¡«å†™æ ‡é¢˜"], div.ProseMirror',
                    timeout=60000,
                )
                logger.info("[ä¸Šä¼ ] âœ“ ç¼–è¾‘åŒºå·²æ¸²æŸ“")
            except Exception:
                logger.warning("[ä¸Šä¼ ] ç¼–è¾‘åŒºç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­å°è¯•")
                await page.wait_for_timeout(5000)

            await page.wait_for_timeout(2000)
            await _save_debug_screenshot(page, f"{title}_after_upload")

            # â”€â”€ æ­¥éª¤ 5ï¼šå¡«å†™æ ‡é¢˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # å®æµ‹ï¼šinput.d-textï¼Œplaceholder="å¡«å†™æ ‡é¢˜ä¼šæœ‰æ›´å¤šèµå“¦"
            title_short = title[:20]
            title_input = (
                await page.query_selector('input.d-text')
                or await page.query_selector('input[placeholder*="å¡«å†™æ ‡é¢˜"]')
                or await page.query_selector('input[placeholder*="æ ‡é¢˜"]')
            )
            if title_input:
                await title_input.click()
                await title_input.click(click_count=3)
                await title_input.fill(title_short)
                logger.info(f"[ä¸Šä¼ ] âœ“ å·²å¡«å†™æ ‡é¢˜: {title_short}")
            else:
                logger.warning("[ä¸Šä¼ ] æœªæ‰¾åˆ°æ ‡é¢˜è¾“å…¥æ¡†ï¼Œè·³è¿‡")

            await page.wait_for_timeout(500)

            # â”€â”€ æ­¥éª¤ 6ï¼šå¡«å†™æ­£æ–‡æè¿° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # å®æµ‹ï¼šdiv.tiptap.ProseMirror[contenteditable="true"]ï¼ˆProseMirror å¯Œæ–‡æœ¬ï¼‰
            # ProseMirror ä¸æ”¯æŒ fill()ï¼Œå¿…é¡» click() åç”¨ keyboard.type()
            desc_input = (
                await page.query_selector('div.tiptap.ProseMirror[contenteditable="true"]')
                or await page.query_selector('div.ProseMirror[contenteditable="true"]')
                or await page.query_selector('div.tiptap[contenteditable="true"]')
            )
            # é™çº§ï¼šæ‰¾æ‰€æœ‰å¯è§ contenteditableï¼Œå–ç¬¬ä¸€ä¸ªéæ ‡é¢˜çš„
            if not desc_input:
                all_editable = await page.query_selector_all('div[contenteditable="true"]')
                visible_editable = []
                for el in all_editable:
                    if await el.is_visible():
                        visible_editable.append(el)
                if visible_editable:
                    desc_input = visible_editable[0]
                    logger.info(f"[ä¸Šä¼ ] é™çº§ï¼šæ‰¾åˆ° {len(visible_editable)} ä¸ªå¯è§ contenteditableï¼Œå–ç¬¬1ä¸ª")

            if desc_input:
                await desc_input.click()
                await page.wait_for_timeout(300)
                full_desc = description if description else title
                # ProseMirror éœ€è¦ç”¨ keyboard.type è€Œé fill
                await page.keyboard.type(full_desc, delay=30)
                logger.info(f"[ä¸Šä¼ ] âœ“ å·²å¡«å†™æ­£æ–‡ ({len(full_desc)} å­—)")
            else:
                logger.warning("[ä¸Šä¼ ] æœªæ‰¾åˆ°æ­£æ–‡è¾“å…¥æ¡†ï¼Œè·³è¿‡")

            await page.wait_for_timeout(1000)

            # â”€â”€ æ­¥éª¤ 7ï¼šç­‰å¾…ä¸Šä¼ å®Œæˆï¼Œç‚¹å‡»å‘å¸ƒæŒ‰é’® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # å›¾ç‰‡/è§†é¢‘ä¸Šä¼ åˆ°æœåŠ¡å™¨éœ€è¦æ—¶é—´ï¼Œå‘å¸ƒæŒ‰é’®å¯èƒ½å¤„äº disabled çŠ¶æ€
            # ç­–ç•¥ï¼šæœ€å¤šç­‰ 120 ç§’ï¼ˆ10æ¬¡Ã—12ç§’ï¼‰ï¼Œç›´åˆ°æŒ‰é’®ä» disabled å˜ä¸ºå¯ç”¨
            logger.info("[ä¸Šä¼ ] ç­‰å¾…åª’ä½“ä¸Šä¼ è‡³æœåŠ¡å™¨å®Œæˆ...")

            publish_btn = None
            MAX_WAIT_ROUNDS = 10   # æœ€å¤šé‡è¯•è½®æ•°
            WAIT_PER_ROUND = 12    # æ¯è½®ç­‰å¾…ç§’æ•°

            for attempt in range(MAX_WAIT_ROUNDS):
                # æ£€æŸ¥æ˜¯å¦è¿˜åœ¨ä¸Šä¼ ä¸­ï¼ˆæœ‰è¿›åº¦æ¡/loadingå…ƒç´ ï¼‰
                uploading = await page.query_selector(
                    '[class*="uploading"], [class*="progress"]:not([value="100"]), '
                    '[class*="loading"]:not([class*="button"]):not([class*="btn"])'
                )
                if uploading:
                    logger.info(f"[ä¸Šä¼ ] ç¬¬ {attempt+1} è½®ï¼šæ£€æµ‹åˆ°ä¸Šä¼ è¿›åº¦å…ƒç´ ï¼Œç­‰å¾… {WAIT_PER_ROUND} ç§’...")
                    await page.wait_for_timeout(WAIT_PER_ROUND * 1000)
                    continue

                # æ‰¾å‘å¸ƒæŒ‰é’®ï¼šæ–‡å­—ç²¾ç¡®åŒ¹é…"å‘å¸ƒ"ï¼Œå¯è§ï¼Œæœªç¦ç”¨
                btns = await page.query_selector_all("button")
                for btn in btns:
                    if not await btn.is_visible():
                        continue
                    btn_text = (await btn.inner_text()).strip()
                    is_disabled = await btn.get_attribute("disabled")
                    if btn_text == "å‘å¸ƒ":
                        if is_disabled is None:
                            publish_btn = btn
                            logger.info(f"[ä¸Šä¼ ] âœ“ æ‰¾åˆ°å¯ç”¨å‘å¸ƒæŒ‰é’®ï¼ˆç¬¬ {attempt+1} è½®ï¼‰")
                        else:
                            logger.info(f"[ä¸Šä¼ ] ç¬¬ {attempt+1} è½®ï¼šå‘å¸ƒæŒ‰é’® disabledï¼Œç­‰å¾… {WAIT_PER_ROUND} ç§’...")
                        break

                if publish_btn:
                    break

                await page.wait_for_timeout(WAIT_PER_ROUND * 1000)

            if not publish_btn:
                logger.error(f"[ä¸Šä¼ ] âœ— ç­‰å¾… {MAX_WAIT_ROUNDS * WAIT_PER_ROUND} ç§’åä»æœªæ‰¾åˆ°å¯ç”¨å‘å¸ƒæŒ‰é’®")
                await _save_debug_screenshot(page, f"{title}_no_publish_btn")
                return False

            await publish_btn.scroll_into_view_if_needed()
            await publish_btn.click()
            logger.info("[ä¸Šä¼ ] âœ“ å·²ç‚¹å‡»å‘å¸ƒæŒ‰é’®")

            # â”€â”€ æ­¥éª¤ 8ï¼šç­‰å¾…å‘å¸ƒæˆåŠŸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            await page.wait_for_timeout(3000)
            current_url = page.url

            if "manage" in current_url or "success" in current_url:
                logger.info(f"[ä¸Šä¼ ] âœ“ å‘å¸ƒæˆåŠŸï¼ˆURL è·³è½¬ï¼‰: {title[:30]}")
                return True

            # æŸ¥æ‰¾ toast / æç¤ºå…ƒç´ 
            success_el = await page.query_selector('[class*="success"], [class*="toast"]')
            if success_el:
                success_text = (await success_el.inner_text()).strip()
                logger.info(f"[ä¸Šä¼ ] âœ“ æˆåŠŸæç¤º: '{success_text}'")
                return True

            # å†ç­‰ 5 ç§’
            await page.wait_for_timeout(5000)
            if page.url != CREATOR_URL:
                logger.info(f"[ä¸Šä¼ ] âœ“ ç–‘ä¼¼æˆåŠŸï¼ˆURL å·²å˜åŒ–ï¼‰: {title[:30]}")
                return True

            logger.warning(f"[ä¸Šä¼ ] ? æœªæ£€æµ‹åˆ°æ˜ç¡®æˆåŠŸæ ‡å¿—ï¼Œä¿å®ˆè®°ä¸ºæˆåŠŸ: {title[:30]}")
            await _save_debug_screenshot(page, f"{title}_final")
            return True

        except Exception as e:
            logger.error(f"[ä¸Šä¼ ] âœ— å‘å¸ƒå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            await _save_debug_screenshot(page, f"{title}_error")
            return False

    async def run_upload_session(
        self,
        notes: List[Dict],
        dry_run: bool = False,
        history: Optional[UploadHistory] = None,
    ) -> Tuple[int, int]:
        """
        å¯åŠ¨æµè§ˆå™¨ä¼šè¯ï¼Œæ‰¹é‡ä¸Šä¼ ç¬”è®°ã€‚

        Returns:
            (success_count, fail_count)
        """
        if dry_run:
            logger.info("[è¯•è¿è¡Œ] dry-run æ¨¡å¼ï¼Œä¸æ‰§è¡Œå®é™…ä¸Šä¼ ")
            for i, note in enumerate(notes, 1):
                logger.info(
                    f"  [{i}] ID={note['note_id']} | æ ‡é¢˜={note['title'][:30]} | "
                    f"å›¾ç‰‡={len(note['images'])} | æè¿°={len(note['description'])} å­—"
                )
            return 0, 0

        if not notes:
            logger.info("[ä¸Šä¼ ] æ²¡æœ‰å¾…ä¸Šä¼ çš„ç¬”è®°")
            return 0, 0

        try:
            from playwright.async_api import async_playwright
        except ImportError:
            logger.error("[Playwright] æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install playwright && playwright install chromium")
            return 0, len(notes)

        success = 0
        fail = 0

        # åˆå§‹åŒ– AI æ¶¦è‰²å™¨ï¼ˆåœ¨æµè§ˆå™¨å¯åŠ¨å‰å®Œæˆï¼Œé¿å…å¼‚æ­¥å¹²æ‰°ï¼‰
        ai_polisher = XHSAIPolisher()

        pw = await async_playwright().start()
        browser = await pw.chromium.launch(
            headless=False,
            args=[
                "--disable-blink-features=AutomationControlled",
                "--no-sandbox",
                "--disable-dev-shm-usage",
                "--disable-infobars",
                "--window-size=1280,900",
            ],
        )
        context = await browser.new_context(
            user_agent=(
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/120.0.0.0 Safari/537.36"
            ),
            viewport={"width": 1280, "height": 900},
            locale="zh-CN",
        )
        await context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
            window.chrome = {runtime: {}};
        """)

        try:
            # æ³¨å…¥ Cookie
            injected = await self._inject_cookies(context)
            if injected == 0:
                logger.warning("[ç™»å½•] æœªé…ç½® Cookieï¼Œå°†éœ€è¦æ‰«ç ç™»å½•")

            page = await context.new_page()

            # æ£€æŸ¥ç™»å½•çŠ¶æ€ï¼ˆå¿…è¦æ—¶ç­‰å¾…æ‰«ç ï¼‰
            logged_in = await self._wait_for_login(page)
            if not logged_in:
                logger.error("[ç™»å½•] ç™»å½•å¤±è´¥ï¼Œä¸­æ­¢ä¸Šä¼ ")
                return 0, len(notes)

            # ä¿å­˜ç™»å½•åçš„ Cookie
            await self._save_account(context)

            # é€ä¸€ä¸Šä¼ ç¬”è®°
            for idx, note in enumerate(notes, 1):
                note_id = note["note_id"]
                note_type = note.get("note_type", "image")
                title = note["title"]
                description = note["description"]
                images = note.get("images", [])
                videos = note.get("videos", [])

                type_label = "è§†é¢‘" if note_type == "video" else "å›¾æ–‡"
                logger.info(f"\n{'â”€' * 50}")
                logger.info(f"[è¿›åº¦] {idx}/{len(notes)} â€” [{type_label}] {title[:40]}")
                if note_type == "video":
                    logger.info(f"[è¿›åº¦] ID: {note_id} | è§†é¢‘: {len(videos)} ä¸ª")
                else:
                    logger.info(f"[è¿›åº¦] ID: {note_id} | å›¾ç‰‡: {len(images)} å¼ ")

                # â”€â”€ AI æ¶¦è‰²æ–‡æ¡ˆï¼ˆä¸Šä¼ å‰ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                polished = ai_polisher.polish(title, description)
                upload_title = polished["title"]
                upload_desc = polished["description"]

                ok = await self.upload_note(
                    page, upload_title, upload_desc,
                    image_paths=images,
                    note_type=note_type,
                    video_paths=videos,
                )

                if ok:
                    success += 1
                    if history:
                        history.add(note_id)
                    logger.info(f"[è¿›åº¦] âœ“ ç¬¬ {idx} ç¯‡ä¸Šä¼ æˆåŠŸ")
                    # â”€â”€ Bark æ¨é€é€šçŸ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    bark_notify_success(upload_title)
                else:
                    fail += 1
                    logger.warning(f"[è¿›åº¦] âœ— ç¬¬ {idx} ç¯‡ä¸Šä¼ å¤±è´¥")

                # é¿å…é£æ§ï¼šä¸¤æ¬¡ä¸Šä¼ ä¹‹é—´ä¼‘çœ 
                if idx < len(notes):
                    logger.info(f"[èŠ‚å¥] ç­‰å¾… {UPLOAD_SLEEP} ç§’åç»§ç»­...")
                    await asyncio.sleep(UPLOAD_SLEEP)

        except Exception as e:
            logger.error(f"[ä¼šè¯] æ•´ä½“å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
        finally:
            try:
                await browser.close()
            except Exception:
                pass
            try:
                await pw.stop()
            except Exception:
                pass

        return success, fail


# ==========================================
# è°ƒè¯•å·¥å…·
# ==========================================
async def _save_debug_screenshot(page, label: str):
    """ä¿å­˜è°ƒè¯•æˆªå›¾"""
    try:
        Path("logs").mkdir(exist_ok=True)
        safe_label = re.sub(r'[\\/:*?"<>|]', '_', label)[:30]
        path = f"logs/xhs_upload_debug_{safe_label}.png"
        await page.screenshot(path=path, full_page=True)
        logger.info(f"[è°ƒè¯•] å·²ä¿å­˜æˆªå›¾: {path}")
    except Exception:
        pass


# ==========================================
# ä¸»è°ƒåº¦å™¨
# ==========================================
class XHSUploadScheduler:
    """ä¸Šä¼ è°ƒåº¦å™¨ï¼Œæ”¯æŒå•æ¬¡å’ŒæŒç»­å¾ªç¯æ¨¡å¼"""

    def __init__(
        self,
        download_dir: str = "downloads/xhs_monitor",
        interval: int = 300,
        cookie: str = "",
        account_file: str = "",
        run_once: bool = False,
        dry_run: bool = False,
    ):
        load_dotenv()

        self.download_dir = download_dir or os.getenv("XHS_UPLOAD_DIR", "downloads/xhs_monitor")
        self.interval = interval
        self.run_once = run_once
        self.dry_run = dry_run

        self.history = UploadHistory()
        self.scanner = NoteScanner(self.download_dir, self.history)
        self.uploader = XHSUploader(
            cookie=cookie,
            account_file=account_file,
        )

        logger.info(f"[åˆå§‹åŒ–] ä¸‹è½½ç›®å½•: {self.download_dir}")
        logger.info(f"[åˆå§‹åŒ–] å·²ä¸Šä¼ è®°å½•: {self.history.count()} æ¡")
        logger.info(f"[åˆå§‹åŒ–] æ¨¡å¼: {'è¯•è¿è¡Œ' if dry_run else 'å•æ¬¡' if run_once else 'æŒç»­å¾ªç¯'}")

    async def run_once_round(self) -> Tuple[int, int]:
        """æ‰§è¡Œä¸€è½®æ‰«æ + ä¸Šä¼ """
        notes = self.scanner.scan()
        if not notes:
            return 0, 0

        success, fail = await self.uploader.run_upload_session(
            notes,
            dry_run=self.dry_run,
            history=self.history,
        )
        return success, fail

    async def run(self):
        """å¯åŠ¨ä¸»å¾ªç¯"""
        self._print_banner()

        if self.run_once or self.dry_run:
            logger.info("[è°ƒåº¦] å•æ¬¡æ¨¡å¼ï¼Œæ‰§è¡Œä¸€è½®åé€€å‡º")
            success, fail = await self.run_once_round()
            logger.info(f"[è°ƒåº¦] å®Œæˆ: æˆåŠŸ {success} ç¯‡ï¼Œå¤±è´¥ {fail} ç¯‡")
            return

        # æŒç»­å¾ªç¯
        round_num = 0
        while True:
            round_num += 1
            logger.info(f"\n{'=' * 60}")
            logger.info(f"  ç¬¬ {round_num} è½®ä¸Šä¼   |  {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info(f"{'=' * 60}")

            success, fail = await self.run_once_round()
            logger.info(f"[è°ƒåº¦] æœ¬è½®å®Œæˆ: æˆåŠŸ {success} ç¯‡ï¼Œå¤±è´¥ {fail} ç¯‡")
            logger.info(f"[è°ƒåº¦] {self.interval} ç§’åè¿›è¡Œä¸‹ä¸€è½®æ£€æŸ¥...")
            logger.info(
                f"[è°ƒåº¦] ä¸‹æ¬¡æ—¶é—´: {datetime.fromtimestamp(time.time() + self.interval).strftime('%H:%M:%S')}"
            )

            try:
                await asyncio.sleep(self.interval)
            except asyncio.CancelledError:
                logger.info("[è°ƒåº¦] ä¸Šä¼ å·²åœæ­¢")
                break

    def _print_banner(self):
        print()
        print("=" * 60)
        print("  ğŸ“¤ å°çº¢ä¹¦å›¾æ–‡ç¬”è®°æ‰¹é‡ä¸Šä¼ å·¥å…·")
        print("=" * 60)
        print(f"  ä¸‹è½½ç›®å½•: {self.download_dir}")
        print(f"  å·²ä¸Šä¼ è®°å½•: {self.history.count()} æ¡")
        print(f"  Cookie: {'âœ“ å·²é…ç½®' if self.uploader.cookie else 'âœ— æœªé…ç½®ï¼ˆéœ€æ‰«ç ï¼‰'}")
        print(f"  è´¦å·æ–‡ä»¶: {self.uploader.account_file or 'æœªé…ç½®'}")
        print(f"  æ¨¡å¼: {'ã€è¯•è¿è¡Œã€‘åªæ‰«æä¸ä¸Šä¼ ' if self.dry_run else 'å•æ¬¡' if self.run_once else 'æŒç»­å¾ªç¯'}")
        if not self.dry_run and not self.run_once:
            print(f"  æ£€æŸ¥é—´éš”: {self.interval} ç§’")
        print("=" * 60)
        print()


# ==========================================
# å‘½ä»¤è¡Œå…¥å£
# ==========================================

def parse_args():
    parser = argparse.ArgumentParser(
        description="å°çº¢ä¹¦å›¾æ–‡ç¬”è®°æ‰¹é‡ä¸Šä¼ å·¥å…· â€” ä¸Šä¼  xhs_monitor ä¸‹è½½çš„å†…å®¹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æ‰«æé»˜è®¤ç›®å½•å¹¶ä¸Šä¼ ï¼ˆå•æ¬¡ï¼‰
  python xhs_upload.py --once

  # è¯•è¿è¡Œï¼Œåªæ‰“å°å¾…ä¸Šä¼ å†…å®¹
  python xhs_upload.py --dry-run

  # æŒç»­å¾ªç¯ï¼Œæ¯ 5 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
  python xhs_upload.py --interval 300

  # æŒ‡å®šä¸‹è½½ç›®å½•
  python xhs_upload.py --dir downloads/xhs_monitor --once

  # æŒ‡å®š Cookie
  python xhs_upload.py --cookie "a1=xxx;web_session=yyy" --once
        """,
    )

    parser.add_argument(
        "--dir",
        type=str,
        default="",
        help="ä¸‹è½½ç›®å½•ï¼ˆé»˜è®¤è¯»å– .env çš„ XHS_UPLOAD_DIR æˆ– XHS_MONITOR_DIRï¼‰",
    )
    parser.add_argument(
        "--interval",
        type=int,
        default=0,
        help="è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰ï¼ŒæŒç»­å¾ªç¯æ¨¡å¼æœ‰æ•ˆï¼Œé»˜è®¤ 300 ç§’",
    )
    parser.add_argument(
        "--once",
        action="store_true",
        help="åªè¿è¡Œä¸€è½®åé€€å‡º",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="è¯•è¿è¡Œï¼šåªæ‰«æå’Œæ‰“å°å¾…ä¸Šä¼ å†…å®¹ï¼Œä¸å®é™…ä¸Šä¼ ",
    )
    parser.add_argument(
        "--cookie",
        type=str,
        default="",
        help="å°çº¢ä¹¦ Cookie å­—ç¬¦ä¸²ï¼ˆè¦†ç›– .env é…ç½®ï¼‰",
    )
    parser.add_argument(
        "--account",
        type=str,
        default="",
        help="è´¦å· Cookie JSON æ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›– .env é…ç½®ï¼‰",
    )
    return parser.parse_args()


async def main():
    load_dotenv()
    args = parse_args()

    # ä¸‹è½½ç›®å½•ï¼šå‘½ä»¤è¡Œ > .env XHS_UPLOAD_DIR > .env XHS_MONITOR_DIR > é»˜è®¤å€¼
    download_dir = (
        args.dir
        or os.getenv("XHS_UPLOAD_DIR", "")
        or os.getenv("XHS_MONITOR_DIR", "downloads/xhs_monitor")
    )

    # é—´éš”ï¼šå‘½ä»¤è¡Œ > .env > é»˜è®¤ 300 ç§’
    interval = args.interval or int(os.getenv("XHS_UPLOAD_INTERVAL", "300"))

    scheduler = XHSUploadScheduler(
        download_dir=download_dir,
        interval=interval,
        cookie=args.cookie,
        account_file=args.account,
        run_once=args.once,
        dry_run=args.dry_run,
    )

    try:
        await scheduler.run()
    except KeyboardInterrupt:
        print("\n\n[ä¸­æ–­] ç¨‹åºå·²è¢«ç”¨æˆ·åœæ­¢ (Ctrl+C)")


if __name__ == "__main__":
    asyncio.run(main())
