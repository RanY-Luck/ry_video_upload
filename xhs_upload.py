#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦å›¾æ–‡ç¬”è®°æ‰¹é‡ä¸Šä¼ å·¥å…·

åŠŸèƒ½ï¼š
  - æ‰«æ downloads/xhs_monitor ç›®å½•ï¼ˆxhs_monitor.py çš„ä¸‹è½½è¾“å‡ºï¼‰
  - è¯»å–æ¯ç¯‡ç¬”è®°çš„å›¾ç‰‡ + txt æ–‡æ¡ˆ
  - é€šè¿‡ Playwright æ¨¡æ‹Ÿæµè§ˆå™¨ï¼Œåœ¨ creator.xiaohongshu.com å‘å¸ƒå›¾æ–‡ç¬”è®°
  - ç»´æŠ¤ä¸Šä¼ å†å²è®°å½•ï¼Œé¿å…é‡å¤ä¸Šä¼ 
  - æ”¯æŒ --dry-run æ¨¡å¼ï¼ˆåªæ‰«æï¼Œä¸å®é™…ä¸Šä¼ ï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
  # é»˜è®¤æ¨¡å¼ï¼ˆæŒç»­ç›‘æ§ä¸Šä¼ ï¼‰
  python xhs_upload.py

  # å•æ¬¡è¿è¡Œåé€€å‡º
  python xhs_upload.py --once

  # è¯•è¿è¡Œï¼ˆåªæ‰«ææ‰“å°ï¼Œä¸ä¸Šä¼ ï¼‰
  python xhs_upload.py --dry-run

  # æŒ‡å®šä¸‹è½½ç›®å½•
  python xhs_upload.py --dir downloads/xhs_monitor

  # æŒ‡å®šé—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 300 ç§’
  python xhs_upload.py --interval 600
"""

import argparse
import asyncio
import json
import logging
import os
import re
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from dotenv import load_dotenv

# ==========================================
# æ—¥å¿—é…ç½®
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.StreamHandler(sys.stdout),
    ],
)
logger = logging.getLogger("xhs_upload")

# ==========================================
# å¸¸é‡
# ==========================================
CREATOR_URL = "https://creator.xiaohongshu.com/publish/publish"
LOGIN_URL = "https://creator.xiaohongshu.com"

# å›¾ç‰‡æ”¯æŒçš„æ‰©å±•å
IMAGE_EXTS = {".jpg", ".jpeg", ".png", ".webp", ".gif"}

# è§†é¢‘æ”¯æŒçš„æ‰©å±•å
VIDEO_EXTS = {".mp4", ".mov", ".avi", ".flv", ".mkv", ".webm"}

# ä¸Šä¼ è®°å½•æ–‡ä»¶
HISTORY_FILE = Path("logs/xhs_upload_history.txt")

# ä¸¤æ¬¡ä¸Šä¼ ä¹‹é—´ä¼‘çœ æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé¿å…é£æ§
UPLOAD_SLEEP = 30


# ==========================================
# å†å²è®°å½•ç®¡ç†
# ==========================================
class UploadHistory:
    """ç®¡ç†å·²ä¸Šä¼ ç¬”è®°çš„è®°å½•ï¼Œé¿å…é‡å¤ä¸Šä¼ """

    def __init__(self, history_file: Path = HISTORY_FILE):
        self.history_file = history_file
        self._uploaded: set = self._load()

    def _load(self) -> set:
        if not self.history_file.exists():
            return set()
        try:
            with open(self.history_file, "r", encoding="utf-8") as f:
                return {line.strip() for line in f if line.strip()}
        except Exception as e:
            logger.warning(f"[å†å²] è¯»å–è®°å½•å¤±è´¥: {e}")
            return set()

    def has(self, note_id: str) -> bool:
        return note_id in self._uploaded

    def add(self, note_id: str):
        self._uploaded.add(note_id)
        try:
            self.history_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.history_file, "a", encoding="utf-8") as f:
                f.write(f"{note_id}\n")
        except Exception as e:
            logger.error(f"[å†å²] ä¿å­˜è®°å½•å¤±è´¥: {e}")

    def count(self) -> int:
        return len(self._uploaded)


# ==========================================
# ç¬”è®°å†…å®¹è§£æ
# ==========================================
def parse_note_folder(folder: Path) -> Optional[Dict]:
    """
    è§£æä¸‹è½½çš„ç¬”è®°æ–‡ä»¶å¤¹ï¼Œæå–æ ‡é¢˜ã€æè¿°ã€å›¾ç‰‡/è§†é¢‘è·¯å¾„ã€‚
    è‡ªåŠ¨åˆ¤æ–­ç¬”è®°ç±»å‹ï¼šå« mp4 åˆ™ä¸ºè§†é¢‘ç¬”è®°ï¼Œå¦åˆ™ä¸ºå›¾æ–‡ç¬”è®°ã€‚

    ç›®å½•ç»“æ„ï¼ˆç”± xhs_monitor.py ç”Ÿæˆï¼‰ï¼š
      {note_id}_{æ ‡é¢˜}/
        {æ ‡é¢˜}.txt
        {æ ‡é¢˜}_0.jpg       â† å›¾æ–‡ç¬”è®°
        or
        {æ ‡é¢˜}_0.mp4       â† è§†é¢‘ç¬”è®°

    è¿”å›å­—æ®µï¼š
      note_type: "video" | "image"
      videos:    è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆè§†é¢‘ç¬”è®°æ—¶æœ‰æ•ˆï¼‰
      images:    å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå›¾æ–‡ç¬”è®°æ—¶æœ‰æ•ˆï¼‰
    """
    # ä»æ–‡ä»¶å¤¹åæå– note_idï¼ˆæ ¼å¼ï¼š{note_id}_{æ ‡é¢˜}ï¼‰
    folder_name = folder.name
    parts = folder_name.split("_", 1)
    note_id = parts[0] if len(parts[0]) >= 16 else folder_name  # XHS note_id é€šå¸¸ 24 å­—ç¬¦
    # æ›´ç²¾ç¡®åœ°ä»çœŸå® ID æ ¼å¼æå–
    id_match = re.match(r"^([a-f0-9]{24})", folder_name, re.IGNORECASE)
    if id_match:
        note_id = id_match.group(1)
    else:
        note_id = folder_name  # å…œåº•ä½¿ç”¨æ–‡ä»¶å¤¹åä½œä¸ºå”¯ä¸€ ID

    # æŸ¥æ‰¾ txt æ–‡æ¡ˆæ–‡ä»¶
    txt_files = list(folder.glob("*.txt"))
    if not txt_files:
        logger.debug(f"[æ‰«æ] {folder.name}: æ—  txt æ–‡æ¡ˆæ–‡ä»¶ï¼Œè·³è¿‡")
        return None

    txt_file = txt_files[0]

    # è§£æ txt æ–‡ä»¶
    title = ""
    author = ""
    description = ""
    try:
        content = txt_file.read_text(encoding="utf-8")
        lines = content.splitlines()
        meta_done = False
        desc_lines = []

        for line in lines:
            if not meta_done:
                if line.startswith("æ ‡é¢˜:") or line.startswith("æ ‡é¢˜ï¼š"):
                    title = line.split(":", 1)[-1].strip() if ":" in line else line.split("ï¼š", 1)[-1].strip()
                elif line.startswith("ä½œè€…:") or line.startswith("ä½œè€…ï¼š"):
                    author = line.split(":", 1)[-1].strip() if ":" in line else line.split("ï¼š", 1)[-1].strip()
                elif line.startswith("ID:"):
                    # ä» txt é‡Œè¯»å–çœŸå® note_id
                    real_id = line.split(":", 1)[-1].strip()
                    if real_id:
                        note_id = real_id
                elif line == "" and title:
                    # é‡åˆ°ç¬¬ä¸€ä¸ªç©ºè¡Œï¼ˆä¸”å·²è§£æåˆ°æ ‡é¢˜ï¼‰åï¼Œåç»­å†…å®¹ä¸ºæ­£æ–‡
                    meta_done = True
            else:
                desc_lines.append(line)

        description = "\n".join(desc_lines).strip()
    except Exception as e:
        logger.warning(f"[è§£æ] è¯»å– {txt_file} å¤±è´¥: {e}")
        title = folder_name
        description = ""

    if not title:
        title = folder_name

    # æ”¶é›†è§†é¢‘æ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰
    video_files = sorted(
        [f for f in folder.iterdir() if f.suffix.lower() in VIDEO_EXTS],
        key=lambda x: x.name,
    )

    # æ”¶é›†å›¾ç‰‡æ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰
    image_files = sorted(
        [f for f in folder.iterdir() if f.suffix.lower() in IMAGE_EXTS],
        key=lambda x: x.name,
    )

    # åˆ¤æ–­ç¬”è®°ç±»å‹ï¼šæœ‰è§†é¢‘ä¼˜å…ˆä½œä¸ºè§†é¢‘ç¬”è®°
    if video_files:
        note_type = "video"
        logger.debug(f"[æ‰«æ] {folder.name}: è§†é¢‘ç¬”è®°ï¼ˆ{len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶ï¼‰")
    elif image_files:
        note_type = "image"
        logger.debug(f"[æ‰«æ] {folder.name}: å›¾æ–‡ç¬”è®°ï¼ˆ{len(image_files)} å¼ å›¾ç‰‡ï¼‰")
    else:
        logger.debug(f"[æ‰«æ] {folder.name}: æ— å›¾ç‰‡/è§†é¢‘æ–‡ä»¶ï¼Œè·³è¿‡")
        return None

    return {
        "note_id": note_id,
        "note_type": note_type,    # "video" æˆ– "image"
        "folder": folder,
        "title": title,
        "author": author,
        "description": description,
        "images": image_files,     # å›¾æ–‡ç¬”è®°æ—¶ä½¿ç”¨
        "videos": video_files,     # è§†é¢‘ç¬”è®°æ—¶ä½¿ç”¨
    }


# ==========================================
# ç›®å½•æ‰«æå™¨
# ==========================================
class NoteScanner:
    """æ‰«æ xhs_monitor ä¸‹è½½ç›®å½•ï¼Œæ”¶é›†å¾…ä¸Šä¼ çš„ç¬”è®°"""

    def __init__(self, download_dir: str, history: UploadHistory):
        self.download_dir = Path(download_dir)
        self.history = history

    def scan(self) -> List[Dict]:
        """
        æ‰«æå¹¶è¿”å›æ‰€æœ‰å¾…ä¸Šä¼ çš„ç¬”è®°åˆ—è¡¨ã€‚

        ç›®å½•ç»“æ„ï¼š
          download_dir/
            {ä½œè€…å}/
              {note_id}_{æ ‡é¢˜}/   â† è¿™ä¸€å±‚æ‰æ˜¯ç¬”è®°æ–‡ä»¶å¤¹
        """
        if not self.download_dir.exists():
            logger.warning(f"[æ‰«æ] ä¸‹è½½ç›®å½•ä¸å­˜åœ¨: {self.download_dir}")
            return []

        pending = []

        # éå† {ä½œè€…å} å­ç›®å½•
        for author_dir in sorted(self.download_dir.iterdir()):
            if not author_dir.is_dir():
                continue
            # è·³è¿‡éšè—ç›®å½•ï¼ˆå¦‚ .seenï¼‰
            if author_dir.name.startswith("."):
                continue

            # éå† {note_id}_{æ ‡é¢˜} å­ç›®å½•
            for note_folder in sorted(author_dir.iterdir()):
                if not note_folder.is_dir():
                    continue

                note = parse_note_folder(note_folder)
                if note is None:
                    continue

                if self.history.has(note["note_id"]):
                    logger.debug(f"[æ‰«æ] è·³è¿‡å·²ä¸Šä¼ : {note['note_id']} â€” {note['title'][:20]}")
                    continue

                pending.append(note)

        logger.info(f"[æ‰«æ] å‘ç° {len(pending)} ç¯‡å¾…ä¸Šä¼ ç¬”è®°")
        return pending


# ==========================================
# å°çº¢ä¹¦ä¸Šä¼ å™¨ï¼ˆPlaywrightï¼‰
# ==========================================
class XHSUploader:
    """
    ä½¿ç”¨ Playwright æ¨¡æ‹Ÿæµè§ˆå™¨ï¼Œåœ¨ creator.xiaohongshu.com å‘å¸ƒå›¾æ–‡ç¬”è®°ã€‚
    """

    def __init__(self, cookie: str = "", account_file: str = ""):
        self.cookie = cookie or os.getenv("XHS_COOKIE", "")
        self.account_file = Path(account_file) if account_file else None
        # ä» .env è¯»å–è´¦å·æ–‡ä»¶è·¯å¾„
        if not self.account_file:
            env_account = os.getenv("XHS_UPLOAD_ACCOUNT", "")
            if env_account:
                self.account_file = Path(env_account)

    def _parse_cookie_str(self, cookie_str: str) -> List[Dict]:
        """å°† cookie å­—ç¬¦ä¸²è§£æä¸º Playwright cookie æ ¼å¼"""
        cookies = []
        for item in cookie_str.split(";"):
            item = item.strip()
            if "=" not in item:
                continue
            name, value = item.split("=", 1)
            cookies.append({
                "name": name.strip(),
                "value": value.strip(),
                "domain": ".xiaohongshu.com",
                "path": "/",
            })
        return cookies

    async def _inject_cookies(self, context):
        """å‘æµè§ˆå™¨ä¸Šä¸‹æ–‡æ³¨å…¥ Cookie"""
        injected = 0

        # ä¼˜å…ˆè¯»å–è´¦å· JSON æ–‡ä»¶ï¼ˆPlaywright æ ¼å¼ï¼‰
        if self.account_file and self.account_file.exists():
            try:
                with open(self.account_file, "r", encoding="utf-8") as f:
                    saved = json.load(f)
                cookies = saved if isinstance(saved, list) else saved.get("cookies", [])
                if cookies:
                    await context.add_cookies(cookies)
                    injected = len(cookies)
                    logger.info(f"[ç™»å½•] ä»è´¦å·æ–‡ä»¶æ³¨å…¥ {injected} ä¸ª Cookie: {self.account_file}")
                    return injected
            except Exception as e:
                logger.warning(f"[ç™»å½•] è¯»å–è´¦å·æ–‡ä»¶å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨ XHS_COOKIE å­—ç¬¦ä¸²")

        # ä½¿ç”¨ XHS_COOKIE å­—ç¬¦ä¸²
        if self.cookie:
            cookies = self._parse_cookie_str(self.cookie)
            if cookies:
                await context.add_cookies(cookies)
                injected = len(cookies)
                logger.info(f"[ç™»å½•] ä» XHS_COOKIE æ³¨å…¥ {injected} ä¸ª Cookie")

        return injected

    async def _wait_for_login(self, page) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å·²ç™»å½•ã€‚
        å¦‚æœæœªç™»å½•ï¼Œç­‰å¾…ç”¨æˆ·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨æ‰«ç ï¼Œæœ€å¤šç­‰å¾… 120 ç§’ã€‚
        """
        # è®¿é—®åˆ›ä½œè€…ä¸»é¡µ
        await page.goto(LOGIN_URL, wait_until="domcontentloaded", timeout=30000)
        await page.wait_for_timeout(3000)

        # åˆ¤æ–­æ˜¯å¦éœ€è¦ç™»å½•ï¼ˆURL è·³è½¬åˆ°ç™»å½•é¡µæˆ–å‡ºç°äºŒç»´ç ï¼‰
        current_url = page.url
        if "creator.xiaohongshu.com" in current_url and "login" not in current_url:
            logger.info("[ç™»å½•] âœ“ Cookie æœ‰æ•ˆï¼Œå·²ç™»å½•")
            return True

        # ç­‰å¾…æ‰‹åŠ¨æ‰«ç 
        logger.warning("[ç™»å½•] Cookie æ— æ•ˆæˆ–æœªç™»å½•ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­æ‰«ç ç™»å½•...")
        logger.warning("[ç™»å½•] ç­‰å¾…æœ€å¤š 120 ç§’...")

        for i in range(120):
            await asyncio.sleep(1)
            url = page.url
            if "creator.xiaohongshu.com" in url and "login" not in url:
                logger.info("[ç™»å½•] âœ“ æ‰«ç ç™»å½•æˆåŠŸï¼")
                return True

        logger.error("[ç™»å½•] âœ— ç™»å½•è¶…æ—¶")
        return False

    async def _save_account(self, context):
        """ç™»å½•æˆåŠŸåä¿å­˜ Cookie åˆ°è´¦å·æ–‡ä»¶"""
        if not self.account_file:
            return
        try:
            self.account_file.parent.mkdir(parents=True, exist_ok=True)
            cookies = await context.cookies()
            with open(self.account_file, "w", encoding="utf-8") as f:
                json.dump(cookies, f, ensure_ascii=False, indent=2)
            logger.info(f"[ç™»å½•] Cookie å·²ä¿å­˜åˆ°: {self.account_file}")
        except Exception as e:
            logger.warning(f"[ç™»å½•] ä¿å­˜ Cookie å¤±è´¥: {e}")

    async def upload_note(
        self,
        page,
        title: str,
        description: str,
        image_paths: List[Path],
        note_type: str = "image",
        video_paths: Optional[List[Path]] = None,
    ) -> bool:
        """
        åœ¨ creator.xiaohongshu.com å‘å¸ƒä¸€ç¯‡ç¬”è®°ã€‚

        note_type = "image" â†’ ä¸Šä¼ å›¾æ–‡ï¼ˆimage_paths ä¸ºå›¾ç‰‡åˆ—è¡¨ï¼‰
        note_type = "video" â†’ ä¸Šä¼ è§†é¢‘ï¼ˆvideo_paths[0] ä¸ºè§†é¢‘æ–‡ä»¶ï¼‰

        DOM ç»“æ„ï¼ˆé€šè¿‡å®é™…é¡µé¢æ£€æŸ¥ç¡®è®¤ 2026-02-27ï¼‰ï¼š
          - è§†é¢‘ tab:    div.creator-tabï¼ˆå«æ–‡å­—"ä¸Šä¼ è§†é¢‘"ï¼‰
          - å›¾æ–‡ tab:    div.creator-tabï¼ˆå«æ–‡å­—"ä¸Šä¼ å›¾æ–‡"ï¼‰
          - å›¾ç‰‡ input:  input.upload-inputï¼ˆå›¾æ–‡æ¨¡å¼ accept=".jpg,.jpeg,.png,.webp", multiple=trueï¼‰
          - è§†é¢‘ input:  input.upload-inputï¼ˆè§†é¢‘æ¨¡å¼ accept=".mp4,.mov,.flv..." multiple=falseï¼‰
          - æ ‡é¢˜/æ­£æ–‡:   ä¸Šä¼ åª’ä½“ååŠ¨æ€æ¸²æŸ“
          - å‘å¸ƒæŒ‰é’®:    button å«æ–‡å­—"å‘å¸ƒ"

        Returns:
            True è¡¨ç¤ºå‘å¸ƒæˆåŠŸ
        """
        video_paths = video_paths or []
        type_label = "è§†é¢‘" if note_type == "video" else "å›¾æ–‡"
        logger.info(f"[ä¸Šä¼ ] å¼€å§‹å‘å¸ƒ [{type_label}]: {title[:30]}")
        if note_type == "video":
            logger.info(f"[ä¸Šä¼ ] è§†é¢‘æ–‡ä»¶: {len(video_paths)} ä¸ª")
        else:
            logger.info(f"[ä¸Šä¼ ] å›¾ç‰‡æ•°é‡: {len(image_paths)}")


        try:
            # â”€â”€ æ­¥éª¤ 1ï¼šæ‰“å¼€å‘å¸ƒé¡µï¼Œç­‰å¾…é¡µé¢å®Œæ•´æ¸²æŸ“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            await page.goto(CREATOR_URL, wait_until="domcontentloaded", timeout=30000)
            # ç­‰å¾… creator-tab å‡ºç°ï¼ˆç¡®è®¤é¡µé¢ JS å·²æ¸²æŸ“ï¼‰
            try:
                await page.wait_for_selector(".creator-tab", timeout=10000)
                logger.info("[ä¸Šä¼ ] âœ“ é¡µé¢å·²æ¸²æŸ“ï¼ˆæ£€æµ‹åˆ° .creator-tabï¼‰")
            except Exception:
                logger.warning("[ä¸Šä¼ ] .creator-tab è¶…æ—¶ï¼Œç»§ç»­ç­‰å¾… 3 ç§’")
                await page.wait_for_timeout(3000)

            # â”€â”€ æ­¥éª¤ 2ï¼šåˆ‡æ¢åˆ°å¯¹åº” tabï¼ˆè§†é¢‘ or å›¾æ–‡ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # DOM: div.creator-tab åˆ—è¡¨ï¼Œ"ä¸Šä¼ è§†é¢‘" æˆ– "ä¸Šä¼ å›¾æ–‡"
            tab_keyword = "å›¾æ–‡" if note_type == "image" else "è§†é¢‘"
            switched = False
            tabs = await page.query_selector_all(".creator-tab")
            logger.info(f"[ä¸Šä¼ ] å‘ç° {len(tabs)} ä¸ª .creator-tabï¼Œç›®æ ‡å…³é”®å­—: '{tab_keyword}'")
            for tab in tabs:
                text = (await tab.inner_text()).strip()
                logger.info(f"[ä¸Šä¼ ]   tab æ–‡å­—: '{text}'")
                if tab_keyword in text:
                    await tab.click()
                    await page.wait_for_timeout(1500)
                    logger.info(f"[ä¸Šä¼ ] âœ“ å·²ç‚¹å‡» tab: '{text}'")
                    switched = True
                    break

            if not switched:
                logger.warning(f"[ä¸Šä¼ ] æœªæ‰¾åˆ°å«'{tab_keyword}'çš„ tabï¼Œæˆªå›¾åç»§ç»­")
                await _save_debug_screenshot(page, f"{title}_no_tab")

            # â”€â”€ æ­¥éª¤ 3ï¼šç­‰å¾… input å°±ç»ªï¼Œä¸Šä¼ åª’ä½“æ–‡ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            upload_input = None

            if note_type == "video":
                # è§†é¢‘æ¨¡å¼ï¼šinput.upload-inputï¼Œaccept å« mp4ï¼Œmultiple=false
                try:
                    await page.wait_for_selector(
                        'input.upload-input[accept*="mp4"]',
                        timeout=8000,
                    )
                    upload_input = await page.query_selector('input.upload-input[accept*="mp4"]')
                    logger.info("[ä¸Šä¼ ] âœ“ æ‰¾åˆ°è§†é¢‘ file inputï¼ˆaccept å« mp4ï¼‰")
                except Exception:
                    upload_input = await page.query_selector("input.upload-input")
                    if upload_input:
                        accept = await upload_input.get_attribute("accept") or ""
                        logger.info(f"[ä¸Šä¼ ] âœ“ æ‰¾åˆ° upload-inputï¼ˆé™çº§ï¼Œaccept={accept}ï¼‰")

                if not upload_input:
                    logger.error("[ä¸Šä¼ ] âœ— æœªæ‰¾åˆ°è§†é¢‘ä¸Šä¼  input")
                    await _save_debug_screenshot(page, f"{title}_no_input")
                    return False

                # è§†é¢‘åªå–ç¬¬ä¸€ä¸ªæ–‡ä»¶
                vfile = next((p for p in video_paths if p.exists()), None)
                if not vfile:
                    logger.error("[ä¸Šä¼ ] âœ— è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
                    return False
                logger.info(f"[ä¸Šä¼ ] æ­£åœ¨ä¸Šä¼ è§†é¢‘: {vfile.name}")
                await upload_input.set_input_files(str(vfile.absolute()))

            else:
                # å›¾æ–‡æ¨¡å¼ï¼šinput.upload-inputï¼Œaccept å« jpgï¼Œmultiple=true
                try:
                    await page.wait_for_selector(
                        'input.upload-input[accept*="jpg"]',
                        timeout=8000,
                    )
                    upload_input = await page.query_selector('input.upload-input[accept*="jpg"]')
                    logger.info("[ä¸Šä¼ ] âœ“ æ‰¾åˆ°å›¾æ–‡ file inputï¼ˆaccept å« jpgï¼‰")
                except Exception:
                    upload_input = await page.query_selector("input.upload-input")
                    if upload_input:
                        accept = await upload_input.get_attribute("accept") or ""
                        logger.info(f"[ä¸Šä¼ ] âœ“ æ‰¾åˆ° upload-inputï¼ˆé™çº§ï¼Œaccept={accept}ï¼‰")

                if not upload_input:
                    logger.error("[ä¸Šä¼ ] âœ— æœªæ‰¾åˆ°å›¾ç‰‡ä¸Šä¼  input")
                    await _save_debug_screenshot(page, f"{title}_no_input")
                    return False

                file_list = [str(p.absolute()) for p in image_paths if p.exists()]
                missing = [str(p) for p in image_paths if not p.exists()]
                if missing:
                    logger.warning(f"[ä¸Šä¼ ] ä»¥ä¸‹å›¾ç‰‡ä¸å­˜åœ¨ï¼Œè·³è¿‡: {missing}")
                if not file_list:
                    logger.error("[ä¸Šä¼ ] âœ— æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶å‡ä¸å­˜åœ¨")
                    return False
                logger.info(f"[ä¸Šä¼ ] æ­£åœ¨ä¸Šä¼  {len(file_list)} å¼ å›¾ç‰‡: {[Path(f).name for f in file_list]}")
                await upload_input.set_input_files(file_list)


            # â”€â”€ æ­¥éª¤ 4ï¼šç­‰å¾…å›¾ç‰‡ä¸Šä¼ å¹¶ç­‰ç¼–è¾‘åŒºåŠ¨æ€æ¸²æŸ“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            logger.info("[ä¸Šä¼ ] ç­‰å¾…å›¾ç‰‡ä¸Šä¼ å®ŒæˆåŠç¼–è¾‘åŒºæ¸²æŸ“...")
            try:
                # ä¸Šä¼ åï¼Œé¡µé¢ä¼šåŠ¨æ€æ¸²æŸ“æ ‡é¢˜è¾“å…¥æ¡†
                await page.wait_for_selector(
                    'input[class*="title"], '
                    'input[placeholder*="æ ‡é¢˜"], '
                    'div[contenteditable="true"], '
                    'div[class*="preview-item"], '
                    'div[class*="img-container"]',
                    timeout=60000,
                )
                logger.info("[ä¸Šä¼ ] âœ“ ç¼–è¾‘åŒºå·²æ¸²æŸ“")
            except Exception:
                logger.warning("[ä¸Šä¼ ] ç¼–è¾‘åŒºç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­å°è¯•")
                await page.wait_for_timeout(5000)

            await page.wait_for_timeout(2000)
            await _save_debug_screenshot(page, f"{title}_after_upload")

            # â”€â”€ æ­¥éª¤ 5ï¼šå¡«å†™æ ‡é¢˜ï¼ˆæœ€å¤š 20 å­—ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            title_short = title[:20]
            title_input = (
                await page.query_selector('input[class*="title"]')
                or await page.query_selector('input[placeholder*="æ ‡é¢˜"]')
                or await page.query_selector('input[placeholder*="å¡«å†™"]')
            )
            if title_input:
                await title_input.click()
                await title_input.triple_click()  # å…¨é€‰æ—§å†…å®¹å†å¡«å†™
                await title_input.fill(title_short)
                logger.info(f"[ä¸Šä¼ ] âœ“ å·²å¡«å†™æ ‡é¢˜: {title_short}")
            else:
                logger.warning("[ä¸Šä¼ ] æœªæ‰¾åˆ°æ ‡é¢˜è¾“å…¥æ¡†ï¼Œè·³è¿‡")

            await page.wait_for_timeout(500)

            # â”€â”€ æ­¥éª¤ 6ï¼šå¡«å†™æ­£æ–‡æè¿° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # æ­£æ–‡ç¼–è¾‘å™¨é€šå¸¸æ˜¯ contenteditable divï¼ˆQuill-like ç¼–è¾‘å™¨ï¼‰
            desc_input = (
                await page.query_selector('div.ql-editor[contenteditable="true"]')
                or await page.query_selector('div[contenteditable="true"][class*="editor"]')
                or await page.query_selector('div[contenteditable="true"][data-placeholder*="æ­£æ–‡"]')
                or await page.query_selector('div[contenteditable="true"][placeholder*="æ­£æ–‡"]')
            )
            # é™çº§ï¼šå–ç¬¬äºŒä¸ª contenteditableï¼ˆç¬¬ä¸€ä¸ªé€šå¸¸æ˜¯æ ‡é¢˜åŒºåŸŸï¼‰
            if not desc_input:
                all_editable = await page.query_selector_all('div[contenteditable="true"]')
                if len(all_editable) >= 2:
                    desc_input = all_editable[1]
                    logger.info("[ä¸Šä¼ ] ä½¿ç”¨ç¬¬ 2 ä¸ª contenteditable ä½œä¸ºæ­£æ–‡åŒº")
                elif len(all_editable) == 1:
                    desc_input = all_editable[0]

            if desc_input:
                await desc_input.click()
                full_desc = description if description else title
                try:
                    await desc_input.fill(full_desc)
                except Exception:
                    # éƒ¨åˆ†å¯Œæ–‡æœ¬ç¼–è¾‘å™¨ fill ä¸ç”Ÿæ•ˆï¼Œæ”¹ç”¨ type
                    await page.keyboard.type(full_desc)
                logger.info(f"[ä¸Šä¼ ] âœ“ å·²å¡«å†™æ­£æ–‡ ({len(full_desc)} å­—)")
            else:
                logger.warning("[ä¸Šä¼ ] æœªæ‰¾åˆ°æ­£æ–‡è¾“å…¥æ¡†ï¼Œè·³è¿‡")

            await page.wait_for_timeout(1000)

            # â”€â”€ æ­¥éª¤ 7ï¼šç‚¹å‡»å‘å¸ƒæŒ‰é’® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            publish_btn = None
            # éå†æ‰€æœ‰ buttonï¼Œæ‰¾åˆ°æœªç¦ç”¨ä¸”å«"å‘å¸ƒ"çš„
            for attempt in range(2):
                if attempt == 1:
                    await page.wait_for_timeout(2000)  # å†ç­‰å›¾ç‰‡å¤„ç†å®Œ
                btns = await page.query_selector_all("button")
                for btn in btns:
                    btn_text = (await btn.inner_text()).strip()
                    is_disabled = await btn.get_attribute("disabled")
                    if "å‘å¸ƒ" in btn_text and is_disabled is None:
                        publish_btn = btn
                        logger.info(f"[ä¸Šä¼ ] æ‰¾åˆ°å‘å¸ƒæŒ‰é’®: '{btn_text}'")
                        break
                if publish_btn:
                    break

            if not publish_btn:
                logger.error("[ä¸Šä¼ ] âœ— æœªæ‰¾åˆ°å¯ç”¨çš„å‘å¸ƒæŒ‰é’®")
                await _save_debug_screenshot(page, f"{title}_no_publish_btn")
                return False

            await publish_btn.scroll_into_view_if_needed()
            await publish_btn.click()
            logger.info("[ä¸Šä¼ ] âœ“ å·²ç‚¹å‡»å‘å¸ƒæŒ‰é’®")

            # â”€â”€ æ­¥éª¤ 8ï¼šç­‰å¾…å‘å¸ƒæˆåŠŸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            await page.wait_for_timeout(3000)
            current_url = page.url

            if "manage" in current_url or "success" in current_url:
                logger.info(f"[ä¸Šä¼ ] âœ“ å‘å¸ƒæˆåŠŸï¼ˆURL è·³è½¬ï¼‰: {title[:30]}")
                return True

            # æŸ¥æ‰¾ toast / æç¤ºå…ƒç´ 
            success_el = await page.query_selector('[class*="success"], [class*="toast"]')
            if success_el:
                success_text = (await success_el.inner_text()).strip()
                logger.info(f"[ä¸Šä¼ ] âœ“ æˆåŠŸæç¤º: '{success_text}'")
                return True

            # å†ç­‰ 5 ç§’
            await page.wait_for_timeout(5000)
            if page.url != CREATOR_URL:
                logger.info(f"[ä¸Šä¼ ] âœ“ ç–‘ä¼¼æˆåŠŸï¼ˆURL å·²å˜åŒ–ï¼‰: {title[:30]}")
                return True

            logger.warning(f"[ä¸Šä¼ ] ? æœªæ£€æµ‹åˆ°æ˜ç¡®æˆåŠŸæ ‡å¿—ï¼Œä¿å®ˆè®°ä¸ºæˆåŠŸ: {title[:30]}")
            await _save_debug_screenshot(page, f"{title}_final")
            return True

        except Exception as e:
            logger.error(f"[ä¸Šä¼ ] âœ— å‘å¸ƒå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            await _save_debug_screenshot(page, f"{title}_error")
            return False

    async def run_upload_session(
        self,
        notes: List[Dict],
        dry_run: bool = False,
        history: Optional[UploadHistory] = None,
    ) -> Tuple[int, int]:
        """
        å¯åŠ¨æµè§ˆå™¨ä¼šè¯ï¼Œæ‰¹é‡ä¸Šä¼ ç¬”è®°ã€‚

        Returns:
            (success_count, fail_count)
        """
        if dry_run:
            logger.info("[è¯•è¿è¡Œ] dry-run æ¨¡å¼ï¼Œä¸æ‰§è¡Œå®é™…ä¸Šä¼ ")
            for i, note in enumerate(notes, 1):
                logger.info(
                    f"  [{i}] ID={note['note_id']} | æ ‡é¢˜={note['title'][:30]} | "
                    f"å›¾ç‰‡={len(note['images'])} | æè¿°={len(note['description'])} å­—"
                )
            return 0, 0

        if not notes:
            logger.info("[ä¸Šä¼ ] æ²¡æœ‰å¾…ä¸Šä¼ çš„ç¬”è®°")
            return 0, 0

        try:
            from playwright.async_api import async_playwright
        except ImportError:
            logger.error("[Playwright] æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install playwright && playwright install chromium")
            return 0, len(notes)

        success = 0
        fail = 0

        pw = await async_playwright().start()
        browser = await pw.chromium.launch(
            headless=False,
            args=[
                "--disable-blink-features=AutomationControlled",
                "--no-sandbox",
                "--disable-dev-shm-usage",
                "--disable-infobars",
                "--window-size=1280,900",
            ],
        )
        context = await browser.new_context(
            user_agent=(
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/120.0.0.0 Safari/537.36"
            ),
            viewport={"width": 1280, "height": 900},
            locale="zh-CN",
        )
        await context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
            window.chrome = {runtime: {}};
        """)

        try:
            # æ³¨å…¥ Cookie
            injected = await self._inject_cookies(context)
            if injected == 0:
                logger.warning("[ç™»å½•] æœªé…ç½® Cookieï¼Œå°†éœ€è¦æ‰«ç ç™»å½•")

            page = await context.new_page()

            # æ£€æŸ¥ç™»å½•çŠ¶æ€ï¼ˆå¿…è¦æ—¶ç­‰å¾…æ‰«ç ï¼‰
            logged_in = await self._wait_for_login(page)
            if not logged_in:
                logger.error("[ç™»å½•] ç™»å½•å¤±è´¥ï¼Œä¸­æ­¢ä¸Šä¼ ")
                return 0, len(notes)

            # ä¿å­˜ç™»å½•åçš„ Cookie
            await self._save_account(context)

            # é€ä¸€ä¸Šä¼ ç¬”è®°
            for idx, note in enumerate(notes, 1):
                note_id = note["note_id"]
                note_type = note.get("note_type", "image")
                title = note["title"]
                description = note["description"]
                images = note.get("images", [])
                videos = note.get("videos", [])

                type_label = "è§†é¢‘" if note_type == "video" else "å›¾æ–‡"
                logger.info(f"\n{'â”€' * 50}")
                logger.info(f"[è¿›åº¦] {idx}/{len(notes)} â€” [{type_label}] {title[:40]}")
                if note_type == "video":
                    logger.info(f"[è¿›åº¦] ID: {note_id} | è§†é¢‘: {len(videos)} ä¸ª")
                else:
                    logger.info(f"[è¿›åº¦] ID: {note_id} | å›¾ç‰‡: {len(images)} å¼ ")

                ok = await self.upload_note(
                    page, title, description,
                    image_paths=images,
                    note_type=note_type,
                    video_paths=videos,
                )

                if ok:
                    success += 1
                    if history:
                        history.add(note_id)
                    logger.info(f"[è¿›åº¦] âœ“ ç¬¬ {idx} ç¯‡ä¸Šä¼ æˆåŠŸ")
                else:
                    fail += 1
                    logger.warning(f"[è¿›åº¦] âœ— ç¬¬ {idx} ç¯‡ä¸Šä¼ å¤±è´¥")

                # é¿å…é£æ§ï¼šä¸¤æ¬¡ä¸Šä¼ ä¹‹é—´ä¼‘çœ 
                if idx < len(notes):
                    logger.info(f"[èŠ‚å¥] ç­‰å¾… {UPLOAD_SLEEP} ç§’åç»§ç»­...")
                    await asyncio.sleep(UPLOAD_SLEEP)

        except Exception as e:
            logger.error(f"[ä¼šè¯] æ•´ä½“å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
        finally:
            try:
                await browser.close()
            except Exception:
                pass
            try:
                await pw.stop()
            except Exception:
                pass

        return success, fail


# ==========================================
# è°ƒè¯•å·¥å…·
# ==========================================
async def _save_debug_screenshot(page, label: str):
    """ä¿å­˜è°ƒè¯•æˆªå›¾"""
    try:
        Path("logs").mkdir(exist_ok=True)
        safe_label = re.sub(r'[\\/:*?"<>|]', '_', label)[:30]
        path = f"logs/xhs_upload_debug_{safe_label}.png"
        await page.screenshot(path=path, full_page=True)
        logger.info(f"[è°ƒè¯•] å·²ä¿å­˜æˆªå›¾: {path}")
    except Exception:
        pass


# ==========================================
# ä¸»è°ƒåº¦å™¨
# ==========================================
class XHSUploadScheduler:
    """ä¸Šä¼ è°ƒåº¦å™¨ï¼Œæ”¯æŒå•æ¬¡å’ŒæŒç»­å¾ªç¯æ¨¡å¼"""

    def __init__(
        self,
        download_dir: str = "downloads/xhs_monitor",
        interval: int = 300,
        cookie: str = "",
        account_file: str = "",
        run_once: bool = False,
        dry_run: bool = False,
    ):
        load_dotenv()

        self.download_dir = download_dir or os.getenv("XHS_UPLOAD_DIR", "downloads/xhs_monitor")
        self.interval = interval
        self.run_once = run_once
        self.dry_run = dry_run

        self.history = UploadHistory()
        self.scanner = NoteScanner(self.download_dir, self.history)
        self.uploader = XHSUploader(
            cookie=cookie,
            account_file=account_file,
        )

        logger.info(f"[åˆå§‹åŒ–] ä¸‹è½½ç›®å½•: {self.download_dir}")
        logger.info(f"[åˆå§‹åŒ–] å·²ä¸Šä¼ è®°å½•: {self.history.count()} æ¡")
        logger.info(f"[åˆå§‹åŒ–] æ¨¡å¼: {'è¯•è¿è¡Œ' if dry_run else 'å•æ¬¡' if run_once else 'æŒç»­å¾ªç¯'}")

    async def run_once_round(self) -> Tuple[int, int]:
        """æ‰§è¡Œä¸€è½®æ‰«æ + ä¸Šä¼ """
        notes = self.scanner.scan()
        if not notes:
            return 0, 0

        success, fail = await self.uploader.run_upload_session(
            notes,
            dry_run=self.dry_run,
            history=self.history,
        )
        return success, fail

    async def run(self):
        """å¯åŠ¨ä¸»å¾ªç¯"""
        self._print_banner()

        if self.run_once or self.dry_run:
            logger.info("[è°ƒåº¦] å•æ¬¡æ¨¡å¼ï¼Œæ‰§è¡Œä¸€è½®åé€€å‡º")
            success, fail = await self.run_once_round()
            logger.info(f"[è°ƒåº¦] å®Œæˆ: æˆåŠŸ {success} ç¯‡ï¼Œå¤±è´¥ {fail} ç¯‡")
            return

        # æŒç»­å¾ªç¯
        round_num = 0
        while True:
            round_num += 1
            logger.info(f"\n{'=' * 60}")
            logger.info(f"  ç¬¬ {round_num} è½®ä¸Šä¼   |  {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info(f"{'=' * 60}")

            success, fail = await self.run_once_round()
            logger.info(f"[è°ƒåº¦] æœ¬è½®å®Œæˆ: æˆåŠŸ {success} ç¯‡ï¼Œå¤±è´¥ {fail} ç¯‡")
            logger.info(f"[è°ƒåº¦] {self.interval} ç§’åè¿›è¡Œä¸‹ä¸€è½®æ£€æŸ¥...")
            logger.info(
                f"[è°ƒåº¦] ä¸‹æ¬¡æ—¶é—´: {datetime.fromtimestamp(time.time() + self.interval).strftime('%H:%M:%S')}"
            )

            try:
                await asyncio.sleep(self.interval)
            except asyncio.CancelledError:
                logger.info("[è°ƒåº¦] ä¸Šä¼ å·²åœæ­¢")
                break

    def _print_banner(self):
        print()
        print("=" * 60)
        print("  ğŸ“¤ å°çº¢ä¹¦å›¾æ–‡ç¬”è®°æ‰¹é‡ä¸Šä¼ å·¥å…·")
        print("=" * 60)
        print(f"  ä¸‹è½½ç›®å½•: {self.download_dir}")
        print(f"  å·²ä¸Šä¼ è®°å½•: {self.history.count()} æ¡")
        print(f"  Cookie: {'âœ“ å·²é…ç½®' if self.uploader.cookie else 'âœ— æœªé…ç½®ï¼ˆéœ€æ‰«ç ï¼‰'}")
        print(f"  è´¦å·æ–‡ä»¶: {self.uploader.account_file or 'æœªé…ç½®'}")
        print(f"  æ¨¡å¼: {'ã€è¯•è¿è¡Œã€‘åªæ‰«æä¸ä¸Šä¼ ' if self.dry_run else 'å•æ¬¡' if self.run_once else 'æŒç»­å¾ªç¯'}")
        if not self.dry_run and not self.run_once:
            print(f"  æ£€æŸ¥é—´éš”: {self.interval} ç§’")
        print("=" * 60)
        print()


# ==========================================
# å‘½ä»¤è¡Œå…¥å£
# ==========================================

def parse_args():
    parser = argparse.ArgumentParser(
        description="å°çº¢ä¹¦å›¾æ–‡ç¬”è®°æ‰¹é‡ä¸Šä¼ å·¥å…· â€” ä¸Šä¼  xhs_monitor ä¸‹è½½çš„å†…å®¹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æ‰«æé»˜è®¤ç›®å½•å¹¶ä¸Šä¼ ï¼ˆå•æ¬¡ï¼‰
  python xhs_upload.py --once

  # è¯•è¿è¡Œï¼Œåªæ‰“å°å¾…ä¸Šä¼ å†…å®¹
  python xhs_upload.py --dry-run

  # æŒç»­å¾ªç¯ï¼Œæ¯ 5 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
  python xhs_upload.py --interval 300

  # æŒ‡å®šä¸‹è½½ç›®å½•
  python xhs_upload.py --dir downloads/xhs_monitor --once

  # æŒ‡å®š Cookie
  python xhs_upload.py --cookie "a1=xxx;web_session=yyy" --once
        """,
    )

    parser.add_argument(
        "--dir",
        type=str,
        default="",
        help="ä¸‹è½½ç›®å½•ï¼ˆé»˜è®¤è¯»å– .env çš„ XHS_UPLOAD_DIR æˆ– XHS_MONITOR_DIRï¼‰",
    )
    parser.add_argument(
        "--interval",
        type=int,
        default=0,
        help="è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰ï¼ŒæŒç»­å¾ªç¯æ¨¡å¼æœ‰æ•ˆï¼Œé»˜è®¤ 300 ç§’",
    )
    parser.add_argument(
        "--once",
        action="store_true",
        help="åªè¿è¡Œä¸€è½®åé€€å‡º",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="è¯•è¿è¡Œï¼šåªæ‰«æå’Œæ‰“å°å¾…ä¸Šä¼ å†…å®¹ï¼Œä¸å®é™…ä¸Šä¼ ",
    )
    parser.add_argument(
        "--cookie",
        type=str,
        default="",
        help="å°çº¢ä¹¦ Cookie å­—ç¬¦ä¸²ï¼ˆè¦†ç›– .env é…ç½®ï¼‰",
    )
    parser.add_argument(
        "--account",
        type=str,
        default="",
        help="è´¦å· Cookie JSON æ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›– .env é…ç½®ï¼‰",
    )
    return parser.parse_args()


async def main():
    load_dotenv()
    args = parse_args()

    # ä¸‹è½½ç›®å½•ï¼šå‘½ä»¤è¡Œ > .env XHS_UPLOAD_DIR > .env XHS_MONITOR_DIR > é»˜è®¤å€¼
    download_dir = (
        args.dir
        or os.getenv("XHS_UPLOAD_DIR", "")
        or os.getenv("XHS_MONITOR_DIR", "downloads/xhs_monitor")
    )

    # é—´éš”ï¼šå‘½ä»¤è¡Œ > .env > é»˜è®¤ 300 ç§’
    interval = args.interval or int(os.getenv("XHS_UPLOAD_INTERVAL", "300"))

    scheduler = XHSUploadScheduler(
        download_dir=download_dir,
        interval=interval,
        cookie=args.cookie,
        account_file=args.account,
        run_once=args.once,
        dry_run=args.dry_run,
    )

    try:
        await scheduler.run()
    except KeyboardInterrupt:
        print("\n\n[ä¸­æ–­] ç¨‹åºå·²è¢«ç”¨æˆ·åœæ­¢ (Ctrl+C)")


if __name__ == "__main__":
    asyncio.run(main())
